{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a7e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #looking for files \n",
    "# import os\n",
    "\n",
    "# def search_files(directory, extension, keyword):\n",
    "#     for root, dirs, files in os.walk(directory):\n",
    "#         # Skip hidden directories\n",
    "#         dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        \n",
    "#         for file in files:\n",
    "#             if file.endswith(extension):\n",
    "#                 file_path = os.path.join(root, file)\n",
    "#                 try:\n",
    "#                     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#                         if keyword in f.read():\n",
    "#                             print(f\"Found '{keyword}' in: {file_path}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "# home_directory = os.path.expanduser('~')\n",
    "# search_files(home_directory, '.ipynb', 'population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32762630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c88df",
   "metadata": {},
   "source": [
    "# TASK 1 - Fire detection: a) Inputs optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892c939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing RS inputs..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LC_Type1</th>\n",
       "      <th>LC_Type2</th>\n",
       "      <th>LC_Type3</th>\n",
       "      <th>LC_Type4</th>\n",
       "      <th>LC_Type5</th>\n",
       "      <th>avgLongitude</th>\n",
       "      <th>avgLatitude</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>...</th>\n",
       "      <th>runoff_sum</th>\n",
       "      <th>total_evaporation_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>snowmelt_sum</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>snow_density</th>\n",
       "      <th>snow_cover</th>\n",
       "      <th>dewpoint_temperature_2m</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>isFire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-162.816950</td>\n",
       "      <td>62.953425</td>\n",
       "      <td>76</td>\n",
       "      <td>0.127839</td>\n",
       "      <td>275.667218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.690267e-01</td>\n",
       "      <td>198.237289</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>265.185745</td>\n",
       "      <td>269.474932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-147.158700</td>\n",
       "      <td>64.785600</td>\n",
       "      <td>151</td>\n",
       "      <td>0.267640</td>\n",
       "      <td>346.948073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.543760e-05</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>154.937485</td>\n",
       "      <td>0.102783</td>\n",
       "      <td>276.366584</td>\n",
       "      <td>281.858940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-148.539500</td>\n",
       "      <td>64.364500</td>\n",
       "      <td>174</td>\n",
       "      <td>0.289804</td>\n",
       "      <td>354.668166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>100.002263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>281.229359</td>\n",
       "      <td>291.656452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-146.508500</td>\n",
       "      <td>63.993100</td>\n",
       "      <td>580</td>\n",
       "      <td>0.545915</td>\n",
       "      <td>285.295886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.360212e-06</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>161.781235</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>270.544548</td>\n",
       "      <td>274.700846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-146.352200</td>\n",
       "      <td>64.024000</td>\n",
       "      <td>453</td>\n",
       "      <td>0.447008</td>\n",
       "      <td>299.675079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.351754e-03</td>\n",
       "      <td>2.640788e-02</td>\n",
       "      <td>267.080388</td>\n",
       "      <td>26.630371</td>\n",
       "      <td>273.304184</td>\n",
       "      <td>282.790248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-161.893500</td>\n",
       "      <td>55.558100</td>\n",
       "      <td>266</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>-0.001935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.725290e-09</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>100.041977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.887743</td>\n",
       "      <td>283.055663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-161.890900</td>\n",
       "      <td>55.562800</td>\n",
       "      <td>266</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>100.024724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.829071</td>\n",
       "      <td>279.656916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-161.875700</td>\n",
       "      <td>55.560600</td>\n",
       "      <td>196</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>100.024724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.829071</td>\n",
       "      <td>279.656916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-161.887600</td>\n",
       "      <td>55.558150</td>\n",
       "      <td>225</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>6.897748e-05</td>\n",
       "      <td>5.452474e-03</td>\n",
       "      <td>181.796534</td>\n",
       "      <td>5.496419</td>\n",
       "      <td>272.464273</td>\n",
       "      <td>274.284028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-161.888817</td>\n",
       "      <td>55.558500</td>\n",
       "      <td>225</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.083240e-04</td>\n",
       "      <td>6.876628e-03</td>\n",
       "      <td>167.100896</td>\n",
       "      <td>7.117025</td>\n",
       "      <td>272.704004</td>\n",
       "      <td>274.018060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4155 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LC_Type1  LC_Type2  LC_Type3  LC_Type4  LC_Type5  avgLongitude  \\\n",
       "0            8       8.0         4         4         4   -162.816950   \n",
       "1            8       8.0         4         4         4   -147.158700   \n",
       "2            8       8.0         4         1         1   -148.539500   \n",
       "3            7       7.0         2         1         5   -146.508500   \n",
       "4            7       7.0         2         1         5   -146.352200   \n",
       "...        ...       ...       ...       ...       ...           ...   \n",
       "4150         9       9.0         4         4         4   -161.893500   \n",
       "4151         9       9.0         4         4         4   -161.890900   \n",
       "4152         9       9.0         4         4         4   -161.875700   \n",
       "4153         9       9.0         4         4         4   -161.887600   \n",
       "4154         9       9.0         4         4         4   -161.888817   \n",
       "\n",
       "      avgLatitude  Elevation     Slope      Aspect  ...  runoff_sum  \\\n",
       "0       62.953425         76  0.127839  275.667218  ...    0.000868   \n",
       "1       64.785600        151  0.267640  346.948073  ...    0.000046   \n",
       "2       64.364500        174  0.289804  354.668166  ...    0.000249   \n",
       "3       63.993100        580  0.545915  285.295886  ...    0.001994   \n",
       "4       64.024000        453  0.447008  299.675079  ...    0.000587   \n",
       "...           ...        ...       ...         ...  ...         ...   \n",
       "4150    55.558100        266  0.025017  270.000000  ...    0.000754   \n",
       "4151    55.562800        266  0.025017  270.000000  ...    0.002284   \n",
       "4152    55.560600        196  0.025017  270.000000  ...    0.002284   \n",
       "4153    55.558150        225  0.025017  270.000000  ...    0.004974   \n",
       "4154    55.558500        225  0.025017  270.000000  ...    0.003073   \n",
       "\n",
       "      total_evaporation_sum  snowfall_sum  snowmelt_sum    snow_depth  \\\n",
       "0                 -0.000535      0.000005  0.000000e+00  1.690267e-01   \n",
       "1                 -0.002125      0.000000  1.543760e-05 -7.345365e-24   \n",
       "2                 -0.003539      0.000000  0.000000e+00 -7.345365e-24   \n",
       "3                 -0.000478      0.000000  3.360212e-06 -7.345365e-24   \n",
       "4                 -0.000995      0.000000  4.351754e-03  2.640788e-02   \n",
       "...                     ...           ...           ...           ...   \n",
       "4150              -0.001935      0.000000  3.725290e-09 -7.345365e-24   \n",
       "4151              -0.001564      0.000000  0.000000e+00 -7.345365e-24   \n",
       "4152              -0.001564      0.000000  0.000000e+00 -7.345365e-24   \n",
       "4153              -0.000148      0.000004  6.897748e-05  5.452474e-03   \n",
       "4154              -0.000228      0.000028  1.083240e-04  6.876628e-03   \n",
       "\n",
       "      snow_density  snow_cover  dewpoint_temperature_2m  temperature_2m  \\\n",
       "0       198.237289  100.000000               265.185745      269.474932   \n",
       "1       154.937485    0.102783               276.366584      281.858940   \n",
       "2       100.002263    0.000000               281.229359      291.656452   \n",
       "3       161.781235    0.082926               270.544548      274.700846   \n",
       "4       267.080388   26.630371               273.304184      282.790248   \n",
       "...            ...         ...                      ...             ...   \n",
       "4150    100.041977    0.000000               280.887743      283.055663   \n",
       "4151    100.024724    0.000000               277.829071      279.656916   \n",
       "4152    100.024724    0.000000               277.829071      279.656916   \n",
       "4153    181.796534    5.496419               272.464273      274.284028   \n",
       "4154    167.100896    7.117025               272.704004      274.018060   \n",
       "\n",
       "      isFire  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "4150       0  \n",
       "4151       0  \n",
       "4152       0  \n",
       "4153       0  \n",
       "4154       0  \n",
       "\n",
       "[4155 rows x 48 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#read inputs \n",
    "print('Reading and processing RS inputs..')\n",
    "data = pd.read_csv('FireDetection_datasetV4_0Days.csv', header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac54941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare sequences\n",
    "def prepare_data(df, target, features):\n",
    "    # Initialize an empty list to hold feature columns\n",
    "    feature_columns = []\n",
    "\n",
    "    # Loop through each feature and sequence length to get the corresponding columns\n",
    "    for feature in features:\n",
    "        column_name = f\"{feature}\"\n",
    "        if column_name in df.columns:\n",
    "            feature_columns.append(column_name)        \n",
    "        \n",
    "    # Extract the feature columns for X\n",
    "    X = df[feature_columns].values\n",
    "    \n",
    "    # Extract the target column for y\n",
    "    y = df[target].values\n",
    "    \n",
    "    feature_columns.append(target)\n",
    "    \n",
    "    return X, y, df[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1483e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modellearning(trgt, selected_features):\n",
    "    X, y, _ = prepare_data(data, trgt, selected_features)\n",
    "#     print(X.shape)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    all_indices = list(range(len(data)))\n",
    "    train_ind, test_ind = train_test_split(all_indices, test_size=0.2, random_state=42, stratify=data[\"isFire\"])\n",
    "    \n",
    "    X_train, X_test = X[train_ind], X[test_ind]\n",
    "    y_train, y_test = np.squeeze(y[train_ind]), np.squeeze(y[test_ind])\n",
    "\n",
    "    # Scale features\n",
    "    X_train_scaled, X_test_scaled = scale_features(X_train, X_test)  \n",
    "\n",
    "    # Train final ExtraTreesClassifier model under finetuned parameters\n",
    "    model_final = HistGradientBoostingClassifier(random_state=42)#, #normal#V4\n",
    "                                                 #learning_rate=0.2130,#0.121945,  # ensure learning_rate is at least 0.01\n",
    "                                                 #max_iter=783,#1167,\n",
    "                                                 #max_depth=19,#3,\n",
    "                                                 #min_samples_leaf=4,#3,\n",
    "                                                 #l2_regularization=0.1096,#0.1466,  # ensure l2_regularization is non-negative\n",
    "                                                 #max_leaf_nodes=63)#38)\n",
    "    model_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_test = model_final.predict(X_test_scaled)  # Reshape the data to 2D if needed\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    return accuracy_test\n",
    "\n",
    "# Function to scale features\n",
    "def scale_features(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae583a-de35-415a-88a2-9e6d4951f9dd",
   "metadata": {},
   "source": [
    "####### Do not use this following cell but the following one as this one is an old version of a single stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97668c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Start optimization: Fire Detection\n",
      "gen\tnevals\n",
      "0  \t499   \n",
      "1  \t280   \n",
      "2  \t319   \n",
      "3  \t320   \n",
      "4  \t294   \n",
      "5  \t316   \n",
      "6  \t290   \n",
      "7  \t315   \n",
      "8  \t306   \n",
      "9  \t313   \n",
      "10 \t306   \n",
      "11 \t310   \n",
      "12 \t324   \n",
      "13 \t286   \n",
      "14 \t303   \n",
      "15 \t295   \n",
      "\n",
      "['LC_Type1', 'avgLatitude', 'Slope', 'Aspect', 'H', 'surface_pressure', 'snowfall_sum', 'snowmelt_sum', 'snow_cover']; 0.9061371841155235\n"
     ]
    }
   ],
   "source": [
    "# !pip install deap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "# Dictionary to store ACCURACY for evaluated feature combinations\n",
    "evaluated_combinations = {}\n",
    "\n",
    "# Objective function for GA\n",
    "def evalOneMax(individual, all_feature_names, target):\n",
    "    selected_features = [all_feature_names[i] for i, is_selected in enumerate(individual) if is_selected]\n",
    "#     print(selected_features, end=':')\n",
    "    selected_features_tuple = tuple(sorted(selected_features))\n",
    "    \n",
    "    # Ensure at least 1 feature are selected\n",
    "    if len(selected_features) < 0:\n",
    "        return -float('inf'),\n",
    "    \n",
    "    # Always proceed with model training, bypassing the cache check\n",
    "    acc = modellearning(target, selected_features)\n",
    "#     print(np.round(acc*100,3), end=',')#\n",
    "    return (acc,)\n",
    "\n",
    "def optimize_features(target, nmbr_population, nmbr_generation, known_good_features=None):\n",
    "    best_features = []  # Initialize to an empty list\n",
    "    best_acc = -float('inf')  # Initialize to negative infinity\n",
    "    \n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(all_feature_names))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    \n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", evalOneMax, all_feature_names=all_feature_names, target=target)\n",
    "\n",
    "    population = toolbox.population(n=nmbr_population)\n",
    "\n",
    "    # Seed the population with a known good individual, if provided\n",
    "    if known_good_features:\n",
    "        good_individual = [0] * len(all_feature_names)\n",
    "        for feature in known_good_features:\n",
    "            idx = all_feature_names.index(feature)\n",
    "            good_individual[idx] = 1\n",
    "        population[0] = creator.Individual(good_individual)\n",
    "        population[0].fitness.values = evalOneMax(population[0], all_feature_names, target)\n",
    "\n",
    "    algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=nmbr_generation, verbose=1)\n",
    "\n",
    "    # Extract the best individual\n",
    "    best_ind = tools.selBest(population, k=1)[0]\n",
    "    best_features = [all_feature_names[i] for i, is_selected in enumerate(best_ind) if is_selected]\n",
    "    best_acc = best_ind.fitness.values[0]\n",
    "    \n",
    "    return best_features, best_acc\n",
    "\n",
    "# Your data loading here\n",
    "target = 'isFire'\n",
    "all_feature_names = list(data.columns[:-1])\n",
    "known_good_features = ['LST_Day_1km','LST_Night_1km']  # Replace with your own known good features\n",
    "nmbr_population = 500\n",
    "nmbr_generation = 15\n",
    "\n",
    "## Run optimization\n",
    "print(f'*** Start optimization: Fire Detection')\n",
    "best_features, best_acc = optimize_features(target, nmbr_population, nmbr_generation, known_good_features)\n",
    "print(f\"\\n{best_features}; {best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1047899-12bf-4893-82e0-2d009e044f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Initial optimization: Fire Detection\n",
      "\n",
      "Initial Best Features: ['LC_Type1', 'avgLatitude', 'Slope', 'Aspect', 'H', 'surface_pressure', 'snowfall_sum', 'snowmelt_sum', 'snow_cover']; Initial Best Accuracy: 0.906137184\n",
      "*** Refinement optimization: Fire Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed.ahajjam/.local/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/mohamed.ahajjam/.local/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t50    \n",
      "1  \t37    \n",
      "2  \t19    \n",
      "3  \t28    \n",
      "4  \t28    \n",
      "5  \t30    \n",
      "6  \t30    \n",
      "7  \t35    \n",
      "8  \t32    \n",
      "9  \t28    \n",
      "10 \t36    \n",
      "11 \t27    \n",
      "12 \t26    \n",
      "13 \t28    \n",
      "14 \t30    \n",
      "15 \t31    \n",
      "16 \t28    \n",
      "17 \t33    \n",
      "18 \t32    \n",
      "19 \t34    \n",
      "20 \t37    \n",
      "\n",
      "Refined Best Features: ['LC_Type1', 'avgLatitude', 'Slope', 'Aspect', 'H', 'snowfall_sum']; Refined Best Accuracy: 0.9133574007220217\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "# Dictionary to store ACCURACY for evaluated feature combinations\n",
    "evaluated_combinations = {}\n",
    "\n",
    "# Objective function for GA\n",
    "def evalOneMax(individual, all_feature_names, target):\n",
    "    selected_features = [all_feature_names[i] for i, is_selected in enumerate(individual) if is_selected]\n",
    "    selected_features_tuple = tuple(sorted(selected_features))\n",
    "    \n",
    "    # Ensure at least 1 feature is selected\n",
    "    if len(selected_features) < 1:\n",
    "        return -float('inf'),\n",
    "    \n",
    "    # Always proceed with model training, bypassing the cache check\n",
    "    acc = modellearning(target, selected_features)\n",
    "    return (acc,)\n",
    "\n",
    "def optimize_features(target, all_feature_names, nmbr_population, nmbr_generation, known_good_features=None):\n",
    "    best_features = []  # Initialize to an empty list\n",
    "    best_acc = -float('inf')  # Initialize to negative infinity\n",
    "    \n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(all_feature_names))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    \n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", evalOneMax, all_feature_names=all_feature_names, target=target)\n",
    "\n",
    "    population = toolbox.population(n=nmbr_population)\n",
    "\n",
    "    # Seed the population with a known good individual, if provided\n",
    "    if known_good_features:\n",
    "        good_individual = [0] * len(all_feature_names)\n",
    "        for feature in known_good_features:\n",
    "            idx = all_feature_names.index(feature)\n",
    "            good_individual[idx] = 1\n",
    "        population[0] = creator.Individual(good_individual)\n",
    "        population[0].fitness.values = evalOneMax(population[0], all_feature_names, target)\n",
    "\n",
    "    algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=nmbr_generation, verbose=1)\n",
    "\n",
    "    # Extract the best individual\n",
    "    best_ind = tools.selBest(population, k=1)[0]\n",
    "    best_features = [all_feature_names[i] for i, is_selected in enumerate(best_ind) if is_selected]\n",
    "    best_acc = best_ind.fitness.values[0]\n",
    "    \n",
    "    return best_features, best_acc\n",
    "\n",
    "# Your data loading here\n",
    "data = pd.read_csv('FireDetection_datasetV4_0Days.csv', header=0)\n",
    "target = 'isFire'\n",
    "all_feature_names = list(data.columns[:-1])\n",
    "known_good_features = ['LST_Day_1km', 'LST_Night_1km']  # Replace with your own known good features\n",
    "\n",
    "# # Initial GA Run to find a smaller subset of features\n",
    "# nmbr_population_initial = 500\n",
    "# nmbr_generation_initial = 15\n",
    "print(f'*** Initial optimization: Fire Detection')\n",
    "initial_best_features, initial_best_acc = ['LC_Type1', 'avgLatitude', 'Slope', 'Aspect', 'H', 'surface_pressure', 'snowfall_sum', 'snowmelt_sum', 'snow_cover'], 0.906137184\n",
    "#optimize_features(target, all_feature_names, nmbr_population_initial, nmbr_generation_initial, known_good_features)\n",
    "print(f\"\\nInitial Best Features: {initial_best_features}; Initial Best Accuracy: {initial_best_acc}\")\n",
    "\n",
    "# Refinement GA Run on the smaller subset of features\n",
    "nmbr_population_refinement = 50\n",
    "nmbr_generation_refinement = 20\n",
    "print(f'*** Refinement optimization: Fire Detection')\n",
    "refined_best_features, refined_best_acc = optimize_features(target, initial_best_features, nmbr_population_refinement, nmbr_generation_refinement)\n",
    "print(f\"\\nRefined Best Features: {refined_best_features}; Refined Best Accuracy: {refined_best_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81f60e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133574007220217"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellearning(target, ['LC_Type1', 'avgLatitude', 'Slope', 'Aspect', 'snowfall_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d91822e",
   "metadata": {},
   "source": [
    "# TASK 2 - Burnt area estimation : a) Inputs optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e13a4865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing RS inputs..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LC_Type1</th>\n",
       "      <th>LC_Type2</th>\n",
       "      <th>LC_Type3</th>\n",
       "      <th>LC_Type4</th>\n",
       "      <th>LC_Type5</th>\n",
       "      <th>avgLongitude</th>\n",
       "      <th>avgLatitude</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>...</th>\n",
       "      <th>runoff_sum</th>\n",
       "      <th>total_evaporation_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>snowmelt_sum</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>snow_density</th>\n",
       "      <th>snow_cover</th>\n",
       "      <th>dewpoint_temperature_2m</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>totalArea_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-162.81695</td>\n",
       "      <td>62.953425</td>\n",
       "      <td>76</td>\n",
       "      <td>0.127839</td>\n",
       "      <td>275.667218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.690267e-01</td>\n",
       "      <td>198.237289</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>265.185745</td>\n",
       "      <td>269.474932</td>\n",
       "      <td>0.979713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-147.15870</td>\n",
       "      <td>64.785600</td>\n",
       "      <td>151</td>\n",
       "      <td>0.267640</td>\n",
       "      <td>346.948073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.543760e-05</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>154.937485</td>\n",
       "      <td>0.102783</td>\n",
       "      <td>276.366584</td>\n",
       "      <td>281.858940</td>\n",
       "      <td>0.295989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-148.53950</td>\n",
       "      <td>64.364500</td>\n",
       "      <td>174</td>\n",
       "      <td>0.289804</td>\n",
       "      <td>354.668166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>100.002263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>281.229359</td>\n",
       "      <td>291.656452</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-146.50850</td>\n",
       "      <td>63.993100</td>\n",
       "      <td>580</td>\n",
       "      <td>0.545915</td>\n",
       "      <td>285.295886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.360212e-06</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>161.781235</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>270.544548</td>\n",
       "      <td>274.700846</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-146.35220</td>\n",
       "      <td>64.024000</td>\n",
       "      <td>453</td>\n",
       "      <td>0.447008</td>\n",
       "      <td>299.675079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.351754e-03</td>\n",
       "      <td>2.640788e-02</td>\n",
       "      <td>267.080388</td>\n",
       "      <td>26.630371</td>\n",
       "      <td>273.304184</td>\n",
       "      <td>282.790248</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-145.93715</td>\n",
       "      <td>64.643550</td>\n",
       "      <td>313</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>334.382444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.450581e-09</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>105.813136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.222176</td>\n",
       "      <td>287.991054</td>\n",
       "      <td>0.830562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-161.88630</td>\n",
       "      <td>55.418800</td>\n",
       "      <td>2186</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.294075e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>180.705714</td>\n",
       "      <td>40.343750</td>\n",
       "      <td>281.538507</td>\n",
       "      <td>282.846760</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-161.89350</td>\n",
       "      <td>55.417900</td>\n",
       "      <td>2479</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.279286e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>180.694321</td>\n",
       "      <td>40.343750</td>\n",
       "      <td>278.835497</td>\n",
       "      <td>280.776448</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-161.89090</td>\n",
       "      <td>55.422600</td>\n",
       "      <td>2100</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.418032e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>194.436834</td>\n",
       "      <td>40.363200</td>\n",
       "      <td>275.874074</td>\n",
       "      <td>277.500503</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-161.87570</td>\n",
       "      <td>55.420400</td>\n",
       "      <td>1823</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.418032e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>194.436834</td>\n",
       "      <td>40.363200</td>\n",
       "      <td>275.874074</td>\n",
       "      <td>277.500503</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2070 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LC_Type1  LC_Type2  LC_Type3  LC_Type4  LC_Type5  avgLongitude  \\\n",
       "0            8         8         4         4         4    -162.81695   \n",
       "1            8         8         4         4         4    -147.15870   \n",
       "2            8         8         4         1         1    -148.53950   \n",
       "3            7         7         2         1         5    -146.50850   \n",
       "4            7         7         2         1         5    -146.35220   \n",
       "...        ...       ...       ...       ...       ...           ...   \n",
       "2065         8         8         4         1         1    -145.93715   \n",
       "2066        15        15         9         7        10    -161.88630   \n",
       "2067        15        15         9         7        10    -161.89350   \n",
       "2068        15        15         9         7        10    -161.89090   \n",
       "2069        15        15         9         7        10    -161.87570   \n",
       "\n",
       "      avgLatitude  Elevation     Slope      Aspect  ...  runoff_sum  \\\n",
       "0       62.953425         76  0.127839  275.667218  ...    0.000868   \n",
       "1       64.785600        151  0.267640  346.948073  ...    0.000046   \n",
       "2       64.364500        174  0.289804  354.668166  ...    0.000249   \n",
       "3       63.993100        580  0.545915  285.295886  ...    0.001994   \n",
       "4       64.024000        453  0.447008  299.675079  ...    0.000587   \n",
       "...           ...        ...       ...         ...  ...         ...   \n",
       "2065    64.643550        313  0.400006  334.382444  ...    0.000534   \n",
       "2066    55.418800       2186  0.025017  270.000000  ...    0.006850   \n",
       "2067    55.417900       2479  0.025017  270.000000  ...    0.006829   \n",
       "2068    55.422600       2100  0.025017  270.000000  ...    0.004876   \n",
       "2069    55.420400       1823  0.025017  270.000000  ...    0.004876   \n",
       "\n",
       "      total_evaporation_sum  snowfall_sum  snowmelt_sum    snow_depth  \\\n",
       "0                 -0.000535      0.000005  0.000000e+00  1.690267e-01   \n",
       "1                 -0.002125      0.000000  1.543760e-05 -7.345365e-24   \n",
       "2                 -0.003539      0.000000  0.000000e+00 -7.345365e-24   \n",
       "3                 -0.000478      0.000000  3.360212e-06 -7.345365e-24   \n",
       "4                 -0.000995      0.000000  4.351754e-03  2.640788e-02   \n",
       "...                     ...           ...           ...           ...   \n",
       "2065              -0.002531      0.000000  7.450581e-09 -7.345365e-24   \n",
       "2066              -0.000637      0.000000  6.294075e-03  1.344824e+01   \n",
       "2067              -0.001089      0.000000  6.279286e-03  1.344824e+01   \n",
       "2068              -0.000546      0.000000  3.418032e-03  1.344824e+01   \n",
       "2069              -0.000546      0.000000  3.418032e-03  1.344824e+01   \n",
       "\n",
       "      snow_density  snow_cover  dewpoint_temperature_2m  temperature_2m  \\\n",
       "0       198.237289  100.000000               265.185745      269.474932   \n",
       "1       154.937485    0.102783               276.366584      281.858940   \n",
       "2       100.002263    0.000000               281.229359      291.656452   \n",
       "3       161.781235    0.082926               270.544548      274.700846   \n",
       "4       267.080388   26.630371               273.304184      282.790248   \n",
       "...            ...         ...                      ...             ...   \n",
       "2065    105.813136    0.000000               280.222176      287.991054   \n",
       "2066    180.705714   40.343750               281.538507      282.846760   \n",
       "2067    180.694321   40.343750               278.835497      280.776448   \n",
       "2068    194.436834   40.363200               275.874074      277.500503   \n",
       "2069    194.436834   40.363200               275.874074      277.500503   \n",
       "\n",
       "      totalArea_km2  \n",
       "0          0.979713  \n",
       "1          0.295989  \n",
       "2          0.250000  \n",
       "3          0.250000  \n",
       "4          0.250000  \n",
       "...             ...  \n",
       "2065       0.830562  \n",
       "2066       0.250000  \n",
       "2067       0.250000  \n",
       "2068       0.250000  \n",
       "2069       0.250000  \n",
       "\n",
       "[2070 rows x 48 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#read inputs \n",
    "print('Reading and processing RS inputs..')\n",
    "data = pd.read_csv('FireBurntArea_dataset_0Days.csv', header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e75dc112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare sequences\n",
    "def prepare_data(df, target, features):\n",
    "    # Initialize an empty list to hold feature columns\n",
    "    feature_columns = []\n",
    "\n",
    "    # Loop through each feature and sequence length to get the corresponding columns\n",
    "    for feature in features:\n",
    "        column_name = f\"{feature}\"\n",
    "        if column_name in df.columns:\n",
    "            feature_columns.append(column_name)        \n",
    "        \n",
    "    # Extract the feature columns for X\n",
    "    X = df[feature_columns].values\n",
    "    \n",
    "    # Extract the target column for y\n",
    "    y = df[target].values\n",
    "    \n",
    "    feature_columns.append(target)\n",
    "    \n",
    "    return X, y, df[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a949254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def mean_absolute_scaled_error(y_true, y_pred, y_train):\n",
    "    \"\"\"\n",
    "    Compute the Mean Absolute Scaled Error (MASE).\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: array-like of shape (n_samples,) - Ground truth (correct) target values.\n",
    "    y_pred: array-like of shape (n_samples,) - Estimated target values.\n",
    "    y_train: array-like of shape (n_samples,) - Training data to calculate the naive forecast.\n",
    "\n",
    "    Returns:\n",
    "    mase: float - Mean Absolute Scaled Error.\n",
    "    \"\"\"\n",
    "    # Check for the length of y_train\n",
    "    if len(y_train) < 2:\n",
    "        raise ValueError(\"Length of y_train should be at least 2.\")\n",
    "\n",
    "    # Calculate MAE for the predictions\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Calculate the MAE of the one-step naive forecast method\n",
    "    naive_forecast = y_train[:-1]\n",
    "    naive_true = y_train[1:]\n",
    "    mae_naive = mean_absolute_error(naive_true, naive_forecast)\n",
    "\n",
    "    # Handle the case when naive MAE is zero to avoid division by zero\n",
    "    if mae_naive == 0:\n",
    "        return np.inf if mae != 0 else 0\n",
    "\n",
    "    # Calculate MASE\n",
    "    mase = mae / mae_naive\n",
    "\n",
    "    return mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d6aad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "def modellearning(trgt, selected_features):\n",
    "    X, y, _ = prepare_data(data, trgt, selected_features)\n",
    "#     print(X.shape)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    all_indices = list(range(len(data)))\n",
    "    train_ind, test_ind = train_test_split(all_indices, test_size=0.2, random_state=42, stratify=None)\n",
    "    \n",
    "    X_train, X_test = X[train_ind], X[test_ind]\n",
    "    y_train, y_test = np.squeeze(y[train_ind]), np.squeeze(y[test_ind])\n",
    "\n",
    "    # Scale features\n",
    "    X_train_scaled, X_test_scaled = scale_features(X_train, X_test)  \n",
    "\n",
    "    # Train final ExtraTreesClassifier model under finetuned parameters\n",
    "    model_final = HistGradientBoostingRegressor(random_state=42)#ExtraTreesRegressor(n_jobs=-1, random_state=42, max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=70)\n",
    "    model_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_test = model_final.predict(X_test_scaled)  # Reshape the data to 2D if needed\n",
    "\n",
    "    # Evaluate the model\n",
    "    mase_test = mean_absolute_scaled_error(y_test, y_pred_test, y_train)\n",
    "    return mase_test\n",
    "\n",
    "# Function to scale features\n",
    "def scale_features(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75a35350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Initial optimization: Fire Burnt area\n",
      "\n",
      "Initial Best Features: ['LC_Type1', 'LC_Type3', 'LC_Type4', 'avgLongitude', 'EVI', 'sur_refl_b02', 'Albedo_BSA_nir', 'Albedo_BSA_shortwave', 'Albedo_WSA_nir', 'dayl', 'LST_Day_1km', 'LST_Night_1km', 'Y', 'M', 'D', 'H', 'v_component_of_wind_10m', 'surface_pressure', 'total_evaporation_sum', 'snowfall_sum', 'snowmelt_sum', 'snow_cover', 'temperature_2m']; Initial Best Accuracy: 0.7306982670616932\n",
      "*** Refinement optimization: Fire Burnt area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed.ahajjam/.local/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/mohamed.ahajjam/.local/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t50    \n",
      "1  \t26    \n",
      "2  \t30    \n",
      "3  \t30    \n",
      "4  \t29    \n",
      "5  \t25    \n",
      "6  \t32    \n",
      "7  \t29    \n",
      "8  \t37    \n",
      "9  \t34    \n",
      "10 \t26    \n",
      "11 \t33    \n",
      "12 \t45    \n",
      "13 \t37    \n",
      "14 \t30    \n",
      "15 \t29    \n",
      "16 \t31    \n",
      "17 \t32    \n",
      "18 \t33    \n",
      "19 \t30    \n",
      "20 \t32    \n",
      "21 \t34    \n",
      "22 \t25    \n",
      "23 \t31    \n",
      "24 \t28    \n",
      "25 \t34    \n",
      "26 \t30    \n",
      "27 \t31    \n",
      "28 \t26    \n",
      "29 \t25    \n",
      "30 \t36    \n",
      "\n",
      "Refined Best Features: ['LC_Type3', 'avgLongitude', 'EVI', 'Albedo_BSA_nir', 'dayl', 'Y', 'D', 'H', 'v_component_of_wind_10m', 'surface_pressure', 'snowmelt_sum', 'snow_cover']; Refined Best Accuracy: 0.7538299596403665\n"
     ]
    }
   ],
   "source": [
    "# !pip install deap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "# Dictionary to store MASE for evaluated feature combinations\n",
    "evaluated_combinations = {}\n",
    "\n",
    "# Objective function for GA\n",
    "def evalOneMax(individual, all_feature_names, target):\n",
    "    selected_features = [all_feature_names[i] for i, is_selected in enumerate(individual) if is_selected]\n",
    "#     print(selected_features, end=':')\n",
    "    selected_features_tuple = tuple(sorted(selected_features))\n",
    "    \n",
    "    # Ensure at least 1 feature are selected\n",
    "    if len(selected_features) < 0:\n",
    "        return float('inf'),\n",
    "    \n",
    "    # Always proceed with model training, bypassing the cache check\n",
    "    mase = modellearning(target, selected_features)\n",
    "#     print(np.round(mase*100,3), end=',')#\n",
    "    return (mase,)\n",
    "\n",
    "def optimize_features(target, all_feature_names, nmbr_population, nmbr_generation, known_good_features=None):\n",
    "    best_features = []  # Initialize to an empty list\n",
    "    best_mase = float('inf')  # Initialize to negative infinity\n",
    "    \n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(all_feature_names))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    \n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", evalOneMax, all_feature_names=all_feature_names, target=target)\n",
    "\n",
    "    population = toolbox.population(n=nmbr_population)\n",
    "\n",
    "    # Seed the population with a known good individual, if provided\n",
    "    if known_good_features:\n",
    "        good_individual = [0] * len(all_feature_names)\n",
    "        for feature in known_good_features:\n",
    "            idx = all_feature_names.index(feature)\n",
    "            good_individual[idx] = 1\n",
    "        population[0] = creator.Individual(good_individual)\n",
    "        population[0].fitness.values = evalOneMax(population[0], all_feature_names, target)\n",
    "\n",
    "    algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=nmbr_generation, verbose=True)\n",
    "\n",
    "    # Extract the best individual\n",
    "    best_ind = tools.selBest(population, k=1)[0]\n",
    "    best_features = [all_feature_names[i] for i, is_selected in enumerate(best_ind) if is_selected]\n",
    "    best_mase = best_ind.fitness.values[0]\n",
    "    \n",
    "    return best_features, best_mase\n",
    "\n",
    "# Your data loading here\n",
    "target = 'totalArea_km2'\n",
    "all_feature_names = list(data.columns[:-1])\n",
    "known_good_features = ['LST_Day_1km','LST_Night_1km']  # Replace with your own known good features\n",
    "\n",
    "# # Initial GA Run to find a smaller subset of features\n",
    "# nmbr_population_initial = 500\n",
    "# nmbr_generation_initial = 15\n",
    "print(f'*** Initial optimization: Fire Burnt area')\n",
    "initial_best_features, initial_best_acc = ['LC_Type1', 'LC_Type3', 'LC_Type4', 'avgLongitude', 'EVI', 'sur_refl_b02', 'Albedo_BSA_nir', 'Albedo_BSA_shortwave', 'Albedo_WSA_nir', 'dayl', 'LST_Day_1km', 'LST_Night_1km', 'Y', 'M', 'D', 'H', 'v_component_of_wind_10m', 'surface_pressure', 'total_evaporation_sum', 'snowfall_sum', 'snowmelt_sum', 'snow_cover', 'temperature_2m'], 0.7306982670616932\n",
    "#optimize_features(target, all_feature_names, nmbr_population_initial, nmbr_generation_initial, known_good_features)\n",
    "print(f\"\\nInitial Best Features: {initial_best_features}; Initial Best Accuracy: {initial_best_acc}\")\n",
    "\n",
    "# Refinement GA Run on the smaller subset of features\n",
    "nmbr_population_refinement = 50\n",
    "nmbr_generation_refinement = 20\n",
    "print(f'*** Refinement optimization: Fire Burnt area')\n",
    "refined_best_features, refined_best_acc = optimize_features(target, initial_best_features, nmbr_population_refinement, nmbr_generation_refinement)\n",
    "print(f\"\\nRefined Best Features: {refined_best_features}; Refined Best Accuracy: {refined_best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f86c99a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7319584822213083"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellearning(target, ['LC_Type1', 'avgLongitude', 'EVI', 'Albedo_BSA_nir', 'dayl', 'LST_Night_1km', 'Y', 'M', 'D', 'v_component_of_wind_10m', 'surface_pressure', 'snowmelt_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c38e8",
   "metadata": {},
   "source": [
    "### TASK 3 - Duration estimation : a) Inputs optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9742e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing RS inputs..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LC_Type1</th>\n",
       "      <th>LC_Type2</th>\n",
       "      <th>LC_Type3</th>\n",
       "      <th>LC_Type4</th>\n",
       "      <th>LC_Type5</th>\n",
       "      <th>avgLongitude</th>\n",
       "      <th>avgLatitude</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>...</th>\n",
       "      <th>runoff_sum</th>\n",
       "      <th>total_evaporation_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>snowmelt_sum</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>snow_density</th>\n",
       "      <th>snow_cover</th>\n",
       "      <th>dewpoint_temperature_2m</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-162.81695</td>\n",
       "      <td>62.953425</td>\n",
       "      <td>76</td>\n",
       "      <td>0.127839</td>\n",
       "      <td>275.667218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.690267e-01</td>\n",
       "      <td>198.237289</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>265.185745</td>\n",
       "      <td>269.474932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-147.15870</td>\n",
       "      <td>64.785600</td>\n",
       "      <td>151</td>\n",
       "      <td>0.267640</td>\n",
       "      <td>346.948073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.543760e-05</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>154.937485</td>\n",
       "      <td>0.102783</td>\n",
       "      <td>276.366584</td>\n",
       "      <td>281.858940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-148.53950</td>\n",
       "      <td>64.364500</td>\n",
       "      <td>174</td>\n",
       "      <td>0.289804</td>\n",
       "      <td>354.668166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>100.002263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>281.229359</td>\n",
       "      <td>291.656452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-146.50850</td>\n",
       "      <td>63.993100</td>\n",
       "      <td>580</td>\n",
       "      <td>0.545915</td>\n",
       "      <td>285.295886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.360212e-06</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>161.781235</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>270.544548</td>\n",
       "      <td>274.700846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-146.35220</td>\n",
       "      <td>64.024000</td>\n",
       "      <td>453</td>\n",
       "      <td>0.447008</td>\n",
       "      <td>299.675079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.351754e-03</td>\n",
       "      <td>2.640788e-02</td>\n",
       "      <td>267.080388</td>\n",
       "      <td>26.630371</td>\n",
       "      <td>273.304184</td>\n",
       "      <td>282.790248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-145.93715</td>\n",
       "      <td>64.643550</td>\n",
       "      <td>313</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>334.382444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.450581e-09</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>105.813136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.222176</td>\n",
       "      <td>287.991054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-161.88630</td>\n",
       "      <td>55.418800</td>\n",
       "      <td>2186</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.294075e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>180.705714</td>\n",
       "      <td>40.343750</td>\n",
       "      <td>281.538507</td>\n",
       "      <td>282.846760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-161.89350</td>\n",
       "      <td>55.417900</td>\n",
       "      <td>2479</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.279286e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>180.694321</td>\n",
       "      <td>40.343750</td>\n",
       "      <td>278.835497</td>\n",
       "      <td>280.776448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-161.89090</td>\n",
       "      <td>55.422600</td>\n",
       "      <td>2100</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.418032e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>194.436834</td>\n",
       "      <td>40.363200</td>\n",
       "      <td>275.874074</td>\n",
       "      <td>277.500503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-161.87570</td>\n",
       "      <td>55.420400</td>\n",
       "      <td>1823</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.418032e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>194.436834</td>\n",
       "      <td>40.363200</td>\n",
       "      <td>275.874074</td>\n",
       "      <td>277.500503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2070 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LC_Type1  LC_Type2  LC_Type3  LC_Type4  LC_Type5  avgLongitude  \\\n",
       "0            8         8         4         4         4    -162.81695   \n",
       "1            8         8         4         4         4    -147.15870   \n",
       "2            8         8         4         1         1    -148.53950   \n",
       "3            7         7         2         1         5    -146.50850   \n",
       "4            7         7         2         1         5    -146.35220   \n",
       "...        ...       ...       ...       ...       ...           ...   \n",
       "2065         8         8         4         1         1    -145.93715   \n",
       "2066        15        15         9         7        10    -161.88630   \n",
       "2067        15        15         9         7        10    -161.89350   \n",
       "2068        15        15         9         7        10    -161.89090   \n",
       "2069        15        15         9         7        10    -161.87570   \n",
       "\n",
       "      avgLatitude  Elevation     Slope      Aspect  ...  runoff_sum  \\\n",
       "0       62.953425         76  0.127839  275.667218  ...    0.000868   \n",
       "1       64.785600        151  0.267640  346.948073  ...    0.000046   \n",
       "2       64.364500        174  0.289804  354.668166  ...    0.000249   \n",
       "3       63.993100        580  0.545915  285.295886  ...    0.001994   \n",
       "4       64.024000        453  0.447008  299.675079  ...    0.000587   \n",
       "...           ...        ...       ...         ...  ...         ...   \n",
       "2065    64.643550        313  0.400006  334.382444  ...    0.000534   \n",
       "2066    55.418800       2186  0.025017  270.000000  ...    0.006850   \n",
       "2067    55.417900       2479  0.025017  270.000000  ...    0.006829   \n",
       "2068    55.422600       2100  0.025017  270.000000  ...    0.004876   \n",
       "2069    55.420400       1823  0.025017  270.000000  ...    0.004876   \n",
       "\n",
       "      total_evaporation_sum  snowfall_sum  snowmelt_sum    snow_depth  \\\n",
       "0                 -0.000535      0.000005  0.000000e+00  1.690267e-01   \n",
       "1                 -0.002125      0.000000  1.543760e-05 -7.345365e-24   \n",
       "2                 -0.003539      0.000000  0.000000e+00 -7.345365e-24   \n",
       "3                 -0.000478      0.000000  3.360212e-06 -7.345365e-24   \n",
       "4                 -0.000995      0.000000  4.351754e-03  2.640788e-02   \n",
       "...                     ...           ...           ...           ...   \n",
       "2065              -0.002531      0.000000  7.450581e-09 -7.345365e-24   \n",
       "2066              -0.000637      0.000000  6.294075e-03  1.344824e+01   \n",
       "2067              -0.001089      0.000000  6.279286e-03  1.344824e+01   \n",
       "2068              -0.000546      0.000000  3.418032e-03  1.344824e+01   \n",
       "2069              -0.000546      0.000000  3.418032e-03  1.344824e+01   \n",
       "\n",
       "      snow_density  snow_cover  dewpoint_temperature_2m  temperature_2m  \\\n",
       "0       198.237289  100.000000               265.185745      269.474932   \n",
       "1       154.937485    0.102783               276.366584      281.858940   \n",
       "2       100.002263    0.000000               281.229359      291.656452   \n",
       "3       161.781235    0.082926               270.544548      274.700846   \n",
       "4       267.080388   26.630371               273.304184      282.790248   \n",
       "...            ...         ...                      ...             ...   \n",
       "2065    105.813136    0.000000               280.222176      287.991054   \n",
       "2066    180.705714   40.343750               281.538507      282.846760   \n",
       "2067    180.694321   40.343750               278.835497      280.776448   \n",
       "2068    194.436834   40.363200               275.874074      277.500503   \n",
       "2069    194.436834   40.363200               275.874074      277.500503   \n",
       "\n",
       "      Duration  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "...        ...  \n",
       "2065         1  \n",
       "2066         1  \n",
       "2067         1  \n",
       "2068         1  \n",
       "2069         1  \n",
       "\n",
       "[2070 rows x 48 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#read inputs \n",
    "print('Reading and processing RS inputs..')\n",
    "data = pd.read_csv('FireDuration_dataset_0Days.csv', header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7002022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare sequences\n",
    "def prepare_data(df, target, features):\n",
    "    # Initialize an empty list to hold feature columns\n",
    "    feature_columns = []\n",
    "\n",
    "    # Loop through each feature and sequence length to get the corresponding columns\n",
    "    for feature in features:\n",
    "        column_name = f\"{feature}\"\n",
    "        if column_name in df.columns:\n",
    "            feature_columns.append(column_name)        \n",
    "        \n",
    "    # Extract the feature columns for X\n",
    "    X = df[feature_columns].values\n",
    "    \n",
    "    # Extract the target column for y\n",
    "    y = df[target].values\n",
    "    \n",
    "    feature_columns.append(target)\n",
    "    \n",
    "    return X, y, df[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f9deb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def mean_absolute_scaled_error(y_true, y_pred, y_train):\n",
    "    \"\"\"\n",
    "    Compute the Mean Absolute Scaled Error (MASE).\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: array-like of shape (n_samples,) - Ground truth (correct) target values.\n",
    "    y_pred: array-like of shape (n_samples,) - Estimated target values.\n",
    "    y_train: array-like of shape (n_samples,) - Training data to calculate the naive forecast.\n",
    "\n",
    "    Returns:\n",
    "    mase: float - Mean Absolute Scaled Error.\n",
    "    \"\"\"\n",
    "    # Check for the length of y_train\n",
    "    if len(y_train) < 2:\n",
    "        raise ValueError(\"Length of y_train should be at least 2.\")\n",
    "\n",
    "    # Calculate MAE for the predictions\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Calculate the MAE of the one-step naive forecast method\n",
    "    naive_forecast = y_train[:-1]\n",
    "    naive_true = y_train[1:]\n",
    "    mae_naive = mean_absolute_error(naive_true, naive_forecast)\n",
    "\n",
    "    # Handle the case when naive MAE is zero to avoid division by zero\n",
    "    if mae_naive == 0:\n",
    "        return np.inf if mae != 0 else 0\n",
    "\n",
    "    # Calculate MASE\n",
    "    mase = mae / mae_naive\n",
    "\n",
    "    return mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a12ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modellearning(trgt, selected_features):\n",
    "    X, y, _ = prepare_data(data, trgt, selected_features)\n",
    "#     print(X.shape)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    all_indices = list(range(len(data)))\n",
    "    train_ind, test_ind = train_test_split(all_indices, test_size=0.2, random_state=42, stratify=None)\n",
    "    \n",
    "    X_train, X_test = X[train_ind], X[test_ind]\n",
    "    y_train, y_test = np.squeeze(y[train_ind]), np.squeeze(y[test_ind])\n",
    "\n",
    "    # Scale features\n",
    "    X_train_scaled, X_test_scaled = scale_features(X_train, X_test)  \n",
    "\n",
    "    # Train final ExtraTreesClassifier model under finetuned parameters\n",
    "    model_final = HistGradientBoostingRegressor(random_state=42)#ExtraTreesRegressor(n_jobs=-1, random_state=42, max_depth=15, min_samples_leaf=4, min_samples_split=4, n_estimators=50)\n",
    "    model_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_test = model_final.predict(X_test_scaled)  # Reshape the data to 2D if needed\n",
    "\n",
    "    # Evaluate the model\n",
    "    mase_test = mean_absolute_scaled_error(y_test, y_pred_test, y_train)\n",
    "    return mase_test\n",
    "\n",
    "# Function to scale features\n",
    "def scale_features(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7487401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Initial optimization: Fire Duration\n",
      "\n",
      "Initial Best Features: ['LC_Type1', 'LC_Type2', 'LC_Type3', 'LC_Type4', 'avgLongitude', 'avgLatitude', 'Slope', 'NDVI', 'sur_refl_b07', 'Albedo_WSA_nir', 'Albedo_WSA_shortwave', 'prcp', 'srad', 'tmax', 'Y', 'M', 'D', 'W', 'v_component_of_wind_10m', 'u_component_of_wind_10m', 'runoff_sum', 'snow_depth', 'dewpoint_temperature_2m', 'temperature_2m']; Initial Best Accuracy: 0.540659225\n",
      "*** Refinement optimization: Fire Duration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed.ahajjam/.local/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/mohamed.ahajjam/.local/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t50    \n",
      "1  \t30    \n",
      "2  \t26    \n",
      "3  \t29    \n",
      "4  \t26    \n",
      "5  \t26    \n",
      "6  \t30    \n",
      "7  \t35    \n",
      "8  \t26    \n",
      "9  \t30    \n",
      "10 \t34    \n",
      "11 \t35    \n",
      "12 \t26    \n",
      "13 \t24    \n",
      "14 \t36    \n",
      "15 \t19    \n",
      "16 \t33    \n",
      "17 \t33    \n",
      "18 \t23    \n",
      "19 \t30    \n",
      "20 \t22    \n",
      "\n",
      "Refined Best Features: ['LC_Type2', 'avgLongitude', 'avgLatitude', 'Slope', 'NDVI', 'Albedo_WSA_nir', 'Albedo_WSA_shortwave', 'prcp', 'srad', 'tmax', 'Y', 'M', 'D', 'v_component_of_wind_10m', 'runoff_sum', 'snow_depth', 'dewpoint_temperature_2m']; Refined Best Accuracy: 0.5406069981427012\n"
     ]
    }
   ],
   "source": [
    "# !pip install deap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "# Dictionary to store MASE for evaluated feature combinations\n",
    "evaluated_combinations = {}\n",
    "\n",
    "# Objective function for GA\n",
    "def evalOneMax(individual, all_feature_names, target):\n",
    "    selected_features = [all_feature_names[i] for i, is_selected in enumerate(individual) if is_selected]\n",
    "#     print(selected_features, end=':')\n",
    "    selected_features_tuple = tuple(sorted(selected_features))\n",
    "    \n",
    "    # Ensure at least 1 feature are selected\n",
    "    if len(selected_features) < 0:\n",
    "        return float('inf'),\n",
    "    \n",
    "    # Always proceed with model training, bypassing the cache check\n",
    "    mase = modellearning(target, selected_features)\n",
    "#     print(np.round(mase*100,3), end=',')#\n",
    "    return (mase,)\n",
    "\n",
    "def optimize_features(target, all_feature_names, nmbr_population, nmbr_generation, known_good_features=None):\n",
    "    best_features = []  # Initialize to an empty list\n",
    "    best_mase = float('inf')  # Initialize to negative infinity\n",
    "    \n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(all_feature_names))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    \n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", evalOneMax, all_feature_names=all_feature_names, target=target)\n",
    "\n",
    "    population = toolbox.population(n=nmbr_population)\n",
    "\n",
    "    # Seed the population with a known good individual, if provided\n",
    "    if known_good_features:\n",
    "        good_individual = [0] * len(all_feature_names)\n",
    "        for feature in known_good_features:\n",
    "            idx = all_feature_names.index(feature)\n",
    "            good_individual[idx] = 1\n",
    "        population[0] = creator.Individual(good_individual)\n",
    "        population[0].fitness.values = evalOneMax(population[0], all_feature_names, target)\n",
    "\n",
    "    algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=nmbr_generation, verbose=True)\n",
    "\n",
    "    # Extract the best individual\n",
    "    best_ind = tools.selBest(population, k=1)[0]\n",
    "    best_features = [all_feature_names[i] for i, is_selected in enumerate(best_ind) if is_selected]\n",
    "    best_mase = best_ind.fitness.values[0]\n",
    "    \n",
    "    return best_features, best_mase\n",
    "\n",
    "# Your data loading here\n",
    "target = 'Duration'\n",
    "all_feature_names = list(data.columns[:-1])\n",
    "known_good_features = ['LST_Day_1km','LST_Night_1km']  # Replace with your own known good features\n",
    "\n",
    "# # Initial GA Run to find a smaller subset of features\n",
    "# nmbr_population_initial = 500\n",
    "# nmbr_generation_initial = 15\n",
    "print(f'*** Initial optimization: Fire Duration')\n",
    "initial_best_features, initial_best_acc = ['LC_Type1', 'LC_Type2', 'LC_Type3', 'LC_Type4', 'avgLongitude', 'avgLatitude', 'Slope', 'NDVI', 'sur_refl_b07', 'Albedo_WSA_nir', 'Albedo_WSA_shortwave', 'prcp', 'srad', 'tmax', 'Y', 'M', 'D', 'W', 'v_component_of_wind_10m', 'u_component_of_wind_10m', 'runoff_sum', 'snow_depth', 'dewpoint_temperature_2m', 'temperature_2m'], 0.540659225\n",
    "#optimize_features(target, all_feature_names, nmbr_population_initial, nmbr_generation_initial, known_good_features)\n",
    "print(f\"\\nInitial Best Features: {initial_best_features}; Initial Best Accuracy: {initial_best_acc}\")\n",
    "\n",
    "# Refinement GA Run on the smaller subset of features\n",
    "nmbr_population_refinement = 50\n",
    "nmbr_generation_refinement = 20\n",
    "print(f'*** Refinement optimization: Fire Duration')\n",
    "refined_best_features, refined_best_acc = optimize_features(target, initial_best_features, nmbr_population_refinement, nmbr_generation_refinement)\n",
    "print(f\"\\nRefined Best Features: {refined_best_features}; Refined Best Accuracy: {refined_best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba9a96e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5406069981427012"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellearning(target, ['LC_Type1', 'avgLongitude', 'avgLatitude', 'Slope', 'NDVI', 'Albedo_WSA_nir', 'Albedo_WSA_shortwave', 'prcp', 'srad', 'tmax', 'Y', 'M', 'D', 'v_component_of_wind_10m', 'runoff_sum', 'snow_depth', 'dewpoint_temperature_2m'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f5266",
   "metadata": {},
   "source": [
    "# TASK 1 - Fire detection: model learning (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1c51061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "098b6b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pip in /home/mohamed.ahajjam/.local/lib/python3.9/site-packages (23.3.2)\n",
      "\u001b[33mWARNING: Error parsing requirements for pyproject-api: [Errno 2] No such file or directory: '/cm/local/apps/python39/lib/python3.9/site-packages/pyproject_api-1.5.1.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for virtualenv: [Errno 2] No such file or directory: '/cm/local/apps/python39/lib/python3.9/site-packages/virtualenv-20.21.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for pyproject-api: [Errno 2] No such file or directory: '/cm/local/apps/python39/lib/python3.9/site-packages/pyproject_api-1.5.1.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for virtualenv: [Errno 2] No such file or directory: '/cm/local/apps/python39/lib/python3.9/site-packages/virtualenv-20.21.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mos              : Linux-4.18.0-372.32.1.el8_6.x86_64-x86_64-with-glibc2.28\n",
      "python          : 3.9.18\n",
      "tsai            : 0.3.8\n",
      "fastai          : 2.7.13\n",
      "fastcore        : 1.5.29\n",
      "torch           : 2.0.1+cu117\n",
      "device          : 2 gpus (['Tesla V100-SXM2-32GB', 'Tesla V100-SXM2-32GB'])\n",
      "cpu cores       : 36\n",
      "threads per cpu : 1\n",
      "RAM             : 1511.54 GB\n",
      "GPU memory      : [32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0] GB\n"
     ]
    }
   ],
   "source": [
    "# **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************\n",
    "!pip install --upgrade pip\n",
    "stable = True # Set to True for latest pip version or False for main branch in GitHub\n",
    "!pip install {\"tsai -U\" if stable else \"git+https://github.com/timeseriesAI/tsai.git\"} >> /dev/null\n",
    "from tsai.all import *\n",
    "computer_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "2f8db745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mohamed.ahajjam/FireImpact\n"
     ]
    }
   ],
   "source": [
    "cd '/home/mohamed.ahajjam/FireImpact/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e921a7",
   "metadata": {},
   "source": [
    "# **CONFIGURATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "dbad107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing RS inputs..\n"
     ]
    }
   ],
   "source": [
    "#read inputs \n",
    "print('Reading and processing RS inputs..')\n",
    "features = ['LC_Type1','LC_Type2','LC_Type3','LC_Type4','LC_Type5', 'Elevation', 'NDVI', 'EVI', 'sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b07', 'Clear_day_cov','Clear_night_cov','Albedo_BSA_nir','Albedo_BSA_shortwave','Albedo_WSA_nir','Albedo_WSA_shortwave','prcp', 'srad', 'dayl', 'tmax', 'tmin','LST_Day_1km','LST_Night_1km','Y','M', 'D', 'W', 'H', 'S','v_component_of_wind_10m','u_component_of_wind_10m','surface_pressure','runoff_sum','total_evaporation_sum','snowfall_sum','snowmelt_sum','snow_depth','snow_density','snow_cover','dewpoint_temperature_2m','temperature_2m']\n",
    "base_filename = 'Fires_task1_preprocessed_{}.csv'\n",
    "for feature in features:\n",
    "    locals()[feature] = pd.read_csv(base_filename.format(feature), header=0)\n",
    "\n",
    "#     df = locals()[feature]\n",
    "#     print(df.head(0))\n",
    "\n",
    "# features = ['NDVI', 'EVI']\n",
    "# base_filename = 'Fires_task1_preprocessed_{}.csv'\n",
    "# for feature in features:\n",
    "#     locals()[feature] = pd.read_csv(base_filename.format(feature), header=None)*0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "f08448d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a boolean mask for rows with all elements missing in each dataframe\n",
    "# mask_df1 = tmax.isnull().all(axis=1)\n",
    "# mask_df2 = tmin.isnull().all(axis=1)\n",
    "# mask_df3 = srad.isnull().all(axis=1)\n",
    "# mask_df4 = prcp.isnull().all(axis=1)\n",
    "# mask_df5 = dayl.isnull().all(axis=1)\n",
    "# mask_df6 = NDVI.isnull().all(axis=1)\n",
    "# mask_df7 = EVI.isnull().all(axis=1)\n",
    "# # Combine masks to find rows with all elements missing in at least one dataframe\n",
    "# combined_mask = mask_df1 | mask_df2 | mask_df3 | mask_df4 | mask_df5 | mask_df6 | mask_df7  # Use bitwise OR to combine masks\n",
    "# # Get indices of rows to drop\n",
    "# indices_to_drop = combined_mask[combined_mask].index\n",
    "\n",
    "# features = ['tmax', 'tmin', 'srad', 'prcp', 'dayl', 'NDVI', 'EVI']\n",
    "# for feature in features:\n",
    "#     df = locals()[feature]\n",
    "#     locals()[feature] = df.drop(indices_to_drop)\n",
    "# for feature in features:\n",
    "#     df = locals()[feature]\n",
    "#     locals()[feature] = df.apply(lambda row: row.interpolate(method='linear').ffill().bfill(), axis=1) \n",
    "    \n",
    "# TS = TS.drop(indices_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "afe334c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Processing time-related inputs..')\n",
    "\n",
    "# # !pip install holidays\n",
    "# import holidays\n",
    "# from datetime import datetime\n",
    "# from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# # For holidays in USA\n",
    "# us_holidays = holidays.UnitedStates()\n",
    "\n",
    "# #functions\n",
    "# def get_day(x):\n",
    "#     return x.day\n",
    "# def get_month(x):\n",
    "#     return x.month    \n",
    "# def get_year(x):\n",
    "#     return x.year    \n",
    "# def is_weekend(x):\n",
    "#     return x.weekday() >= 5  # 5 for Saturday, 6 for Sunday\n",
    "# def is_holiday(x):\n",
    "#     return int(x in us_holidays)\n",
    "# def get_astronomical_season(date):\n",
    "#     year = date.year\n",
    "#     # Define the dates for solstices and equinoxes (approximate and may vary)\n",
    "#     spring_equinox = datetime(year, 3, 20)\n",
    "#     summer_solstice = datetime(year, 6, 21)\n",
    "#     fall_equinox = datetime(year, 9, 22)\n",
    "#     winter_solstice = datetime(year, 12, 21)\n",
    "\n",
    "#     if spring_equinox <= date < summer_solstice:\n",
    "#         return 0#'Spring'\n",
    "#     elif summer_solstice <= date < fall_equinox:\n",
    "#         return 1#'Summer'\n",
    "#     elif fall_equinox <= date < winter_solstice:\n",
    "#         return 2#'Fall'\n",
    "#     else:\n",
    "#         return 3#'Winter'\n",
    "\n",
    "# cols = TS.columns[:]\n",
    "# TS[cols] = TS[cols].apply(pd.to_datetime, errors='coerce')\n",
    "# TS_data = TS.iloc[:,:] \n",
    "# TS_D = TS_data.applymap(get_day)\n",
    "# TS_M = TS_data.applymap(get_month)\n",
    "# TS_Y = TS_data.applymap(get_year)\n",
    "# TS_S = TS.applymap(get_astronomical_season)\n",
    "# TS_W = TS.applymap(is_weekend)\n",
    "# TS_H = TS.applymap(is_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "8e508b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming to 3D..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "print('Transforming to 3D..')\n",
    "\n",
    "feature_names = ''\n",
    "\n",
    "features = ['Elevation', 'NDVI', 'EVI', 'sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b07', 'Clear_day_cov','Clear_night_cov','Albedo_BSA_nir','Albedo_BSA_shortwave','Albedo_WSA_nir','Albedo_WSA_shortwave','prcp', 'srad', 'dayl', 'tmax', 'tmin','LST_Day_1km','LST_Night_1km','v_component_of_wind_10m','u_component_of_wind_10m','surface_pressure','runoff_sum','total_evaporation_sum','snowfall_sum','snowmelt_sum','snow_depth','snow_density','snow_cover','dewpoint_temperature_2m','temperature_2m']\n",
    "for feature in features:\n",
    "    df = locals()[feature]\n",
    "    locals()[f'{feature}_data'] = to3d(df.iloc[:,:].values)\n",
    "    feature_names = feature_names + f'{feature}_data' + ','\n",
    "\n",
    "del df\n",
    "\n",
    "features1 = ['LC_Type1','LC_Type2','LC_Type3','LC_Type4','LC_Type5','D','M','Y','S','W','H']\n",
    "for feature in features1:\n",
    "    locals()[f'encoder_{feature}'] = OrdinalEncoder()\n",
    "\n",
    "# transform data\n",
    "features1 = ['LC_Type1','LC_Type2','LC_Type3','LC_Type4','LC_Type5','D','M','Y','S','W','H']\n",
    "for feature in features1:\n",
    "    df = locals()[feature]\n",
    "    enc = locals()[f'encoder_{feature}']\n",
    "    locals()[f'TS_{feature}'] = to3d(enc.fit_transform(df))\n",
    "    feature_names = feature_names + f'TS_{feature}' + ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "f1a27040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Target..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2070, 1, 1)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Processing Target..')\n",
    "\n",
    "wildfire_data = pd.read_csv('Fires_task1_preprocessed_targets.csv')\n",
    "# isFire = wildfire_data['isFire']\n",
    "tmp = wildfire_data[wildfire_data[\"isFire\"]==1]\n",
    "# totalArea_km2 = tmp['totalArea_km2']\n",
    "Duration = tmp['Duration']\n",
    "\n",
    "# Target_data = to3d(isFire.values).reshape(len(isFire), 1, 1)\n",
    "# Target_data = to3d(totalArea_km2.values).reshape(len(totalArea_km2), 1, 1)\n",
    "Target_data = to3d(Duration.values).reshape(len(Duration), 1, 1)\n",
    "Target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "43a8becb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating all data..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2070, 43, 91)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Concatenating all data..')#[feature_names[:-1]]\n",
    "data = np.concatenate([Elevation_data,NDVI_data,EVI_data,sur_refl_b01_data,sur_refl_b02_data,sur_refl_b03_data,sur_refl_b07_data,Clear_day_cov_data,Clear_night_cov_data,Albedo_BSA_nir_data,Albedo_BSA_shortwave_data,Albedo_WSA_nir_data,Albedo_WSA_shortwave_data,prcp_data,srad_data,dayl_data,tmax_data,tmin_data,LST_Day_1km_data,LST_Night_1km_data,v_component_of_wind_10m_data,u_component_of_wind_10m_data,surface_pressure_data,runoff_sum_data,total_evaporation_sum_data,snowfall_sum_data,snowmelt_sum_data,snow_depth_data,snow_density_data,snow_cover_data,dewpoint_temperature_2m_data,temperature_2m_data,TS_LC_Type1,TS_LC_Type2,TS_LC_Type3,TS_LC_Type4,TS_LC_Type5,TS_D,TS_M,TS_Y,TS_S,TS_W,TS_H],axis=1)\n",
    "data = data[wildfire_data[\"isFire\"]==1]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "eb15c01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting to train and test sets..\n",
      "training set:  (1656, 43, 91) (1656, 1) , testing set:  (414, 43, 91) (414, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Splitting to train and test sets..')\n",
    "\n",
    "all_indices = list(range(len(data)))\n",
    "train_ind, test_ind = train_test_split(all_indices, test_size=0.2, random_state=42, stratify=None)\n",
    "\n",
    "X_train, X_test = data[train_ind,:,:], data[test_ind,:,:]\n",
    "y_train, y_test = np.squeeze(Target_data[train_ind], axis=2), np.squeeze(Target_data[test_ind], axis=2)\n",
    "print('training set: ',X_train.shape, y_train.shape, ', testing set: ',X_test.shape, y_test.shape)\n",
    "\n",
    "# splits = get_splits(y_train, valid_size=.2, stratify=True, random_state=42, shuffle=True)\n",
    "splits = get_splits(y_train, valid_size=.2, stratify=None, random_state=42, shuffle=True)\n",
    "\n",
    "# tfms = [None, TSClassification()]\n",
    "tfms = [None, TSRegression()]\n",
    "dsets = TSDatasets(X_train, y_train, tfms=tfms, splits=splits, inplace=True)\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[512, 1048])    \n",
    "batch_tfms = TSStandardize(by_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575939f",
   "metadata": {},
   "source": [
    "## Train using InceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a28ed7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "del lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "e0f242e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>total params</th>\n",
       "      <th>learningrate</th>\n",
       "      <th>train dur.</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test dur.</th>\n",
       "      <th>test rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HydraMultiRocketPlus</td>\n",
       "      <td>53825</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>12.833652</td>\n",
       "      <td>73.391685</td>\n",
       "      <td>83.021469</td>\n",
       "      <td>9.111611</td>\n",
       "      <td>0.397209</td>\n",
       "      <td>8.330618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InceptionTimePlus</td>\n",
       "      <td>474561</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>3.452403</td>\n",
       "      <td>54.531258</td>\n",
       "      <td>73.827438</td>\n",
       "      <td>8.592290</td>\n",
       "      <td>0.054326</td>\n",
       "      <td>8.350722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSTPlus</td>\n",
       "      <td>426369</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>3.448504</td>\n",
       "      <td>66.720459</td>\n",
       "      <td>80.362068</td>\n",
       "      <td>8.964489</td>\n",
       "      <td>0.055052</td>\n",
       "      <td>8.351250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XCMPlus</td>\n",
       "      <td>1038083</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.058583</td>\n",
       "      <td>79.615425</td>\n",
       "      <td>82.869492</td>\n",
       "      <td>9.103268</td>\n",
       "      <td>0.048728</td>\n",
       "      <td>8.402143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTMPlus</td>\n",
       "      <td>67101</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>1.325167</td>\n",
       "      <td>85.291451</td>\n",
       "      <td>92.179443</td>\n",
       "      <td>9.601012</td>\n",
       "      <td>0.041069</td>\n",
       "      <td>8.843102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TransformerRNNPlus</td>\n",
       "      <td>699649</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>2.452474</td>\n",
       "      <td>86.319679</td>\n",
       "      <td>93.960678</td>\n",
       "      <td>9.693332</td>\n",
       "      <td>0.052720</td>\n",
       "      <td>9.001664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TransformerGRUPlus</td>\n",
       "      <td>831745</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>2.524791</td>\n",
       "      <td>88.735992</td>\n",
       "      <td>94.513641</td>\n",
       "      <td>9.721813</td>\n",
       "      <td>0.047252</td>\n",
       "      <td>9.082494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TransformerLSTMPlus</td>\n",
       "      <td>897793</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>2.502380</td>\n",
       "      <td>89.716507</td>\n",
       "      <td>95.200508</td>\n",
       "      <td>9.757074</td>\n",
       "      <td>0.052496</td>\n",
       "      <td>9.122606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   arch  total params  learningrate  train dur.  train loss  \\\n",
       "0  HydraMultiRocketPlus         53825      0.000331   12.833652   73.391685   \n",
       "1     InceptionTimePlus        474561      0.000479    3.452403   54.531258   \n",
       "2               TSTPlus        426369      0.000398    3.448504   66.720459   \n",
       "3               XCMPlus       1038083      0.001000    3.058583   79.615425   \n",
       "4              LSTMPlus         67101      0.019055    1.325167   85.291451   \n",
       "5    TransformerRNNPlus        699649      0.000331    2.452474   86.319679   \n",
       "6    TransformerGRUPlus        831745      0.000229    2.524791   88.735992   \n",
       "7   TransformerLSTMPlus        897793      0.004365    2.502380   89.716507   \n",
       "\n",
       "   valid loss  train rmse  test dur.  test rmse  \n",
       "0   83.021469    9.111611   0.397209   8.330618  \n",
       "1   73.827438    8.592290   0.054326   8.350722  \n",
       "2   80.362068    8.964489   0.055052   8.351250  \n",
       "3   82.869492    9.103268   0.048728   8.402143  \n",
       "4   92.179443    9.601012   0.041069   8.843102  \n",
       "5   93.960678    9.693332   0.052720   9.001664  \n",
       "6   94.513641    9.721813   0.047252   9.082494  \n",
       "7   95.200508    9.757074   0.052496   9.122606  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.pyplot.isjulia_display = False\n",
    "archs = {'TransformerLSTMPlus','TransformerRNNPlus','TransformerGRUPlus','InceptionTimePlus','TSTPlus','HydraMultiRocketPlus','XCMPlus','LSTMPlus'}\n",
    "results = pd.DataFrame(columns=['arch', 'total params', 'learningrate','train dur.', 'train loss', 'valid loss', 'train rmse', 'test dur.', 'test rmse'])\n",
    "i = 0\n",
    "for arch in archs:\n",
    "    print(arch)\n",
    "    learn = TSRegressor(X_train, y_train, splits=splits, path='models', arch=arch, tfms=tfms, batch_tfms=batch_tfms, metrics = [rmse, mae], cbs=None)\n",
    "    try:\n",
    "        lr = learn.lr_find()\n",
    "    except IndexError:\n",
    "        lr = learn.lr_find()\n",
    "            \n",
    "    start = time.time()\n",
    "    learn.fit_one_cycle(10, lr.valley)\n",
    "    elapsed = time.time() - start\n",
    "    vals = learn.recorder.values[-1]\n",
    "\n",
    "    valid_dl = dls.valid\n",
    "\n",
    "    test_ds = valid_dl.dataset.add_test(X_test, y_test)\n",
    "    test_dl = valid_dl.new(test_ds)\n",
    "    start = time.time()\n",
    "#     _, test_targetdata, test_predsdata = learn.get_preds(dl=test_dl, with_decoded=True, save_preds=None, save_targs=None)\n",
    "    _, test_targetdata, test_predsdata = learn.get_X_preds(X_test,y_test, with_decoded=True)\n",
    "    elapsed_te = time.time() - start\n",
    "    d = pd.DataFrame([])\n",
    "    d = np.squeeze(test_targetdata)\n",
    "    dp = pd.DataFrame([])\n",
    "    dp = np.squeeze(test_predsdata)\n",
    "    \n",
    "    matplotlib.pyplot.show()\n",
    "    \n",
    "    results.loc[i] = [arch, count_parameters(learn.model), lr[0], elapsed, vals[0], vals[1], vals[2], elapsed_te, np.sqrt(mean_squared_error(d, dp))]\n",
    "    results.sort_values(by='test rmse', ascending=True, kind='stable', ignore_index=True, inplace=True)\n",
    "    clear_output()\n",
    "    i+= 1\n",
    "    \n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "b441c05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predsdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53eaa8d",
   "metadata": {},
   "source": [
    "## Train using MiniROCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0c246dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last 91days - test accuracy: 76.526% time: 9.580121\n",
      "last 80days - test accuracy: 75.352% time: 8.552251\n",
      "last 70days - test accuracy: 76.643% time: 8.20577\n",
      "last 60days - test accuracy: 76.761% time: 8.28104\n",
      "last 50days - test accuracy: 75.235% time: 7.558111\n",
      "last 40days - test accuracy: 75.000% time: 6.785223\n",
      "last 30days - test accuracy: 74.765% time: 6.688696\n",
      "last 20days - test accuracy: 75.352% time: 6.765083\n",
      "last 10days - test accuracy: 72.418% time: 5.863191\n"
     ]
    }
   ],
   "source": [
    "from tsai.models.MINIROCKET import *\n",
    "for ind in range(0,82,10):\n",
    "    if ind != 0:\n",
    "        ind += 1\n",
    "\n",
    "    model = MiniRocketClassifier()\n",
    "    timer.start(False)\n",
    "    model.fit(X_train[:,:,ind:], np.squeeze(y_train))\n",
    "    t = timer.stop()\n",
    "    print(f'last {91-ind}days - test accuracy: {model.score(X_test[:,:,ind:], np.squeeze(y_test)):.3%} time: {t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c9859fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 5voters - test accuracy: 77.113% time: 24.34734\n",
      "using 10voters - test accuracy: 76.291% time: 25.221944\n",
      "using 15voters - test accuracy: 77.230% time: 27.02399\n",
      "using 20voters - test accuracy: 77.113% time: 27.697414\n",
      "using 25voters - test accuracy: 76.878% time: 28.945308\n",
      "using 30voters - test accuracy: 77.700% time: 31.002284\n",
      "using 35voters - test accuracy: 77.347% time: 34.482399\n",
      "using 40voters - test accuracy: 77.347% time: 49.631105\n",
      "using 45voters - test accuracy: 77.582% time: 54.157747\n"
     ]
    }
   ],
   "source": [
    "from tsai.models.MINIROCKET import *\n",
    "for ind in range(5,50,5):\n",
    "    model = MiniRocketVotingClassifier(n_estimators=ind)\n",
    "    timer.start(False)\n",
    "    model.fit(X_train, np.squeeze(y_train))\n",
    "    t = timer.stop()\n",
    "    print(f'using {ind}voters - test accuracy: {model.score(X_test, np.squeeze(y_test)):.3%} time: {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c1a99",
   "metadata": {},
   "source": [
    "## conventional ML - Fire detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e81a5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, sys, os\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "import pandas as pd\n",
    "# pip install scikit-learn==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b666665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into pandas dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# !pip install sktime\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import time\n",
    "\n",
    "# !pip install PrettyTable\n",
    "from prettytable import PrettyTable\n",
    "models = [\n",
    "    {'model': LogisticRegression(class_weight='balanced', n_jobs=-1, random_state=42, max_iter=50000), 'params': {'C': [0.1, 1, 10]}},\n",
    "    {'model': KNeighborsClassifier(n_jobs=-1), 'params': {'n_neighbors': range(3, 23, 3), 'weights': ['uniform', 'distance'], 'p': [1, 2]}},\n",
    "    {'model': DecisionTreeClassifier(class_weight='balanced', random_state=42), 'params': {'max_depth': range(3, 23, 3), 'min_samples_split': [2, 4, 6, 8], 'min_samples_leaf': [1, 2, 3, 5]}},\n",
    "    {'model': RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=42), 'params': {'n_estimators': [10, 20, 50, 70], 'max_depth': range(3, 23, 3), 'min_samples_split': [2, 4, 6], 'min_samples_leaf': [2, 4, 6]}},\n",
    "    {'model': ExtraTreesClassifier(class_weight='balanced', n_jobs=-1, random_state=42), 'params': {'n_estimators': [10, 20, 50, 70], 'max_depth': range(3, 23, 3), 'min_samples_split': [2, 4, 6], 'min_samples_leaf': [2, 4, 6]}},\n",
    "#     {'model': GradientBoostingClassifier(random_state=42), 'params': {'n_estimators': [100, 200, 500, 1000], 'learning_rate': [0.1, 0.01, 0.001], 'max_depth': range(3, 23, 3)}},\n",
    "    {'model': LGBMClassifier(class_weight='balanced', random_state=42), 'params': {'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 200, 500, 1000], 'num_leaves': [20, 31, 40, 60, 80], 'min_child_samples': range(2, 300, 100)}},\n",
    "    {'model': SVC(class_weight='balanced', random_state=42), 'params': {'C': [0.1, 1, 10], 'gamma': [0.1, 0.01, 1], 'kernel': ['linear', 'rbf', 'sigmoid']}},\n",
    "    {'model': MLPClassifier(max_iter=20000, random_state=42), 'params': {'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100, 50), (75, 35)], 'activation': ['relu', 'tanh'], 'alpha': [0.0001, 0.05]}},\n",
    "]\n",
    "\n",
    "\n",
    "# Function to scale features\n",
    "def scale_features(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a71f71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing RS inputs..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LC_Type1</th>\n",
       "      <th>LC_Type2</th>\n",
       "      <th>LC_Type3</th>\n",
       "      <th>LC_Type4</th>\n",
       "      <th>LC_Type5</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>sur_refl_b01</th>\n",
       "      <th>sur_refl_b02</th>\n",
       "      <th>...</th>\n",
       "      <th>runoff_sum</th>\n",
       "      <th>total_evaporation_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>snowmelt_sum</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>snow_density</th>\n",
       "      <th>snow_cover</th>\n",
       "      <th>dewpoint_temperature_2m</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>isFire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>2110</td>\n",
       "      <td>890</td>\n",
       "      <td>714</td>\n",
       "      <td>1096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.690267e-01</td>\n",
       "      <td>198.237289</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>265.185745</td>\n",
       "      <td>269.474932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>151</td>\n",
       "      <td>2778</td>\n",
       "      <td>1434</td>\n",
       "      <td>1366</td>\n",
       "      <td>2417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>154.937485</td>\n",
       "      <td>0.102783</td>\n",
       "      <td>276.366584</td>\n",
       "      <td>281.858940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>5245</td>\n",
       "      <td>1435</td>\n",
       "      <td>300</td>\n",
       "      <td>962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>100.002263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>281.229359</td>\n",
       "      <td>291.656452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>580</td>\n",
       "      <td>5716</td>\n",
       "      <td>2978</td>\n",
       "      <td>635</td>\n",
       "      <td>2330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>161.781235</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>270.544548</td>\n",
       "      <td>274.700846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>453</td>\n",
       "      <td>3206</td>\n",
       "      <td>757</td>\n",
       "      <td>374</td>\n",
       "      <td>727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>2.640788e-02</td>\n",
       "      <td>267.080388</td>\n",
       "      <td>26.630371</td>\n",
       "      <td>273.304184</td>\n",
       "      <td>282.790248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2186</td>\n",
       "      <td>-619</td>\n",
       "      <td>-151</td>\n",
       "      <td>626</td>\n",
       "      <td>553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010495</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>1.352384e+01</td>\n",
       "      <td>362.406560</td>\n",
       "      <td>69.992513</td>\n",
       "      <td>275.316228</td>\n",
       "      <td>276.918200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2100</td>\n",
       "      <td>-9</td>\n",
       "      <td>-8</td>\n",
       "      <td>4561</td>\n",
       "      <td>4552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>265.172185</td>\n",
       "      <td>40.362874</td>\n",
       "      <td>278.225775</td>\n",
       "      <td>282.281168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1823</td>\n",
       "      <td>-324</td>\n",
       "      <td>-204</td>\n",
       "      <td>2305</td>\n",
       "      <td>2160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>-0.001453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>366.359360</td>\n",
       "      <td>40.874593</td>\n",
       "      <td>278.132499</td>\n",
       "      <td>280.711995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6954</td>\n",
       "      <td>6955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>180.712550</td>\n",
       "      <td>40.343750</td>\n",
       "      <td>278.800532</td>\n",
       "      <td>281.392990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2305</td>\n",
       "      <td>149</td>\n",
       "      <td>25</td>\n",
       "      <td>362</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006134</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>180.687485</td>\n",
       "      <td>40.343750</td>\n",
       "      <td>279.778507</td>\n",
       "      <td>281.915859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4083 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LC_Type1  LC_Type2  LC_Type3  LC_Type4  LC_Type5  Elevation  NDVI   EVI  \\\n",
       "0            8         8         4         4         4         76  2110   890   \n",
       "1            8         8         4         4         4        151  2778  1434   \n",
       "2            8         8         4         1         1        174  5245  1435   \n",
       "3            7         7         2         1         5        580  5716  2978   \n",
       "4            7         7         2         1         5        453  3206   757   \n",
       "...        ...       ...       ...       ...       ...        ...   ...   ...   \n",
       "4078        15        15         9         7        10       2186  -619  -151   \n",
       "4079        15        15         9         7        10       2100    -9    -8   \n",
       "4080        15        15         9         7        10       1823  -324  -204   \n",
       "4081        15        15         9         7        10       2290     0     0   \n",
       "4082        15        15         9         7        10       2305   149    25   \n",
       "\n",
       "      sur_refl_b01  sur_refl_b02  ...  runoff_sum  total_evaporation_sum  \\\n",
       "0              714          1096  ...    0.000868              -0.000535   \n",
       "1             1366          2417  ...    0.000046              -0.002125   \n",
       "2              300           962  ...    0.000249              -0.003539   \n",
       "3              635          2330  ...    0.001994              -0.000478   \n",
       "4              374           727  ...    0.000587              -0.000995   \n",
       "...            ...           ...  ...         ...                    ...   \n",
       "4078           626           553  ...    0.010495              -0.000513   \n",
       "4079          4561          4552  ...    0.004982              -0.001936   \n",
       "4080          2305          2160  ...    0.006634              -0.001453   \n",
       "4081          6954          6955  ...    0.010091              -0.001357   \n",
       "4082           362           373  ...    0.006134              -0.000698   \n",
       "\n",
       "      snowfall_sum  snowmelt_sum    snow_depth  snow_density  snow_cover  \\\n",
       "0         0.000005      0.000000  1.690267e-01    198.237289  100.000000   \n",
       "1         0.000000      0.000015 -7.345365e-24    154.937485    0.102783   \n",
       "2         0.000000      0.000000 -7.345365e-24    100.002263    0.000000   \n",
       "3         0.000000      0.000003 -7.345365e-24    161.781235    0.082926   \n",
       "4         0.000000      0.004352  2.640788e-02    267.080388   26.630371   \n",
       "...            ...           ...           ...           ...         ...   \n",
       "4078      0.000000      0.009712  1.352384e+01    362.406560   69.992513   \n",
       "4079      0.000000      0.003286  1.344824e+01    265.172185   40.362874   \n",
       "4080      0.000000      0.004857  1.344824e+01    366.359360   40.874593   \n",
       "4081      0.000000      0.009177  1.344824e+01    180.712550   40.343750   \n",
       "4082      0.000000      0.005021  1.344824e+01    180.687485   40.343750   \n",
       "\n",
       "      dewpoint_temperature_2m  temperature_2m  isFire  \n",
       "0                  265.185745      269.474932       1  \n",
       "1                  276.366584      281.858940       1  \n",
       "2                  281.229359      291.656452       1  \n",
       "3                  270.544548      274.700846       1  \n",
       "4                  273.304184      282.790248       1  \n",
       "...                       ...             ...     ...  \n",
       "4078               275.316228      276.918200       0  \n",
       "4079               278.225775      282.281168       0  \n",
       "4080               278.132499      280.711995       0  \n",
       "4081               278.800532      281.392990       0  \n",
       "4082               279.778507      281.915859       0  \n",
       "\n",
       "[4083 rows x 44 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read inputs \n",
    "print('Reading and processing RS inputs..')\n",
    "data = pd.read_csv('FireDetection_dataset_sameDay.csv', header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f53847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting to train and test sets..\n",
      "training set:  (3266, 43) (3266,) , testing set:  (817, 43) (817,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "print('Splitting to train and test sets..')\n",
    "all_indices = list(range(len(data)))\n",
    "\n",
    "train_ind, test_ind = train_test_split(all_indices, test_size=0.2, random_state=42, stratify=data[\"isFire\"])\n",
    "\n",
    "X_train, X_test = data.iloc[train_ind,:-1], data.iloc[test_ind,:-1]\n",
    "y_train, y_test = np.squeeze(data.iloc[train_ind,-1]), np.squeeze(data.iloc[test_ind,-1])\n",
    "\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_test_scaled = scale_features(X_train, X_test)  \n",
    "\n",
    "print('training set: ',X_train_scaled.shape, y_train.shape, ', testing set: ',X_test_scaled.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e74b8b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression;{'C': 1};ALL;2.248568058013916;0.9687691365584813;0.9694793536804309;0.022981643676757812;0.9657282741738066;0.9665871121718377\n",
      "KNeighborsClassifier;{'n_neighbors': 6, 'p': 1, 'weights': 'distance'};ALL;0.9046649932861328;1.0;1.0;0.10138869285583496;0.9657282741738066;0.966824644549763\n",
      "DecisionTreeClassifier;{'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 2};ALL;2.658390998840332;0.98683404776485;0.9870832081706218;0.0011065006256103516;0.9657282741738066;0.9664268585131894\n",
      "RandomForestClassifier;{'max_depth': 12, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 20};ALL;24.925634622573853;0.9966319657072872;0.9966857487194938;0.006653785705566406;0.9632802937576499;0.9644549763033176\n",
      "ExtraTreesClassifier;{'max_depth': 21, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50};ALL;11.494246006011963;0.9984690753214942;0.9984907938424389;0.012317895889282227;0.9620563035495716;0.9633136094674556\n",
      "LGBMClassifier;learning_rate: 0.01, min_child_samples: 2, n_estimators: 1000, num_leaves: 60;ALL;5.073795557022095;1.0;1.0;0.00590825080871582;0.9608323133414932;0.9618138424821002\n",
      "SVC;{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'};ALL;2.806753158569336;0.9895897121861604;0.9897897897897898;0.018424272537231445;0.9755201958384333;0.9760765550239234\n",
      "MLPClassifier;{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 50)};ALL;14.984097003936768;1.0;1.0;0.0017025470733642578;0.9767441860465116;0.9771908763505402\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, f1_score\n",
    "\n",
    "for model in models:\n",
    "    print(str(model['model']).split('(')[0],end=';')\n",
    "\n",
    "    # hyperparameter tuning\n",
    "    if str(model['model']).split('(')[0] != 'LinearRegression' and str(model['model']).split('(')[0] != 'LGBMClassifier':\n",
    "        model_final = GridSearchCV(model['model'], model['params'], cv=10, scoring='f1_macro', verbose=0, n_jobs=-1)#n_iter=15,\n",
    "    elif str(model['model']).split('(')[0] == 'LGBMClassifier':\n",
    "        model_final = LGBMClassifier(learning_rate=0.01, min_child_samples=2, n_estimators=1000, num_leaves=60, n_jobs=-1, verbose=-1,force_col_wise=True)\n",
    "    else:\n",
    "        model_final = model['model']\n",
    "#     model_final = GridSearchCV(model['model'], model['params'], cv=10, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)#n_iter=15,\n",
    "\n",
    "    # Train model\n",
    "    start_train = time.time()\n",
    "    model_final.fit(X_train_scaled, y_train)\n",
    "    end_train = time.time()\n",
    "\n",
    "    # Evaluate training performance\n",
    "    y_pred_train = model_final.predict(X_train_scaled)\n",
    "\n",
    "    # Calculate the overall accuracy\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "\n",
    "    train_duration = end_train - start_train\n",
    "\n",
    "    if str(model['model']).split('(')[0] != 'LGBMClassifier':\n",
    "        print(f'{model_final.best_params_};ALL;{train_duration};{accuracy_train};{f1_train}',end=';')\n",
    "    elif str(model['model']).split('(')[0] == 'LGBMClassifier':\n",
    "        print(f'learning_rate: 0.01, min_child_samples: 2, n_estimators: 1000, num_leaves: 60;ALL;{train_duration};{accuracy_train};{f1_train}',end=';')\n",
    "    else:\n",
    "        print(f'-;ALL;{train_duration};{accuracy_train};{f1_train}',end=';')\n",
    "\n",
    "    # Test model\n",
    "    start_test = time.time()\n",
    "    y_pred_test = model_final.predict(X_test_scaled)\n",
    "    end_test = time.time()\n",
    "\n",
    "    # Evaluate testing performance\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    test_duration = end_test - start_test\n",
    "\n",
    "    print(f'{test_duration};{accuracy_test};{f1_test}')#;{explained_variance_test};{r2_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18946d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fee3ddc",
   "metadata": {},
   "source": [
    "## conventional ML - Fire Burnt Area prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a829777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, sys, os\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "import pandas as pd\n",
    "# pip install scikit-learn==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7c28193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into pandas dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# !pip install sktime\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# !pip install PrettyTable\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "models = [{'model': LinearRegression(), 'params': {}},\n",
    "          {'model': SGDRegressor(max_iter=10000, random_state=42), 'params': {'alpha': 10.0 ** -np.arange(1, 7),\n",
    "                                                                               'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n",
    "                                                                               'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                                                                               'learning_rate': ['constant', 'optimal', 'invscaling']}},\n",
    "          {'model': KNeighborsRegressor(n_jobs=-1), 'params': {'n_neighbors': range(3, 23, 3), 'weights': ['uniform', 'distance'], 'p': [1, 2]}},\n",
    "\n",
    "          {'model': RandomForestRegressor(verbose=0, n_jobs=-1, random_state=42), 'params': {'n_estimators': [10, 20, 50, 70],\n",
    "                                                        'max_depth': range(3,23,3),\n",
    "                                                        'min_samples_split': [2, 4, 6],\n",
    "                                                        'min_samples_leaf': [2, 4, 6]}},\n",
    "          {'model': ExtraTreesRegressor(verbose=0, n_jobs=-1, random_state=42), 'params': {'n_estimators': [10, 20, 50, 70],\n",
    "                                                        'max_depth': range(3,23,3),\n",
    "                                                        'min_samples_split': [2, 4, 6],\n",
    "                                                        'min_samples_leaf': [2, 4, 6]}},          \n",
    "          {'model':LGBMRegressor(n_jobs=-1, verbose=-1,force_col_wise=True, random_state=42), 'params': {'learning_rate': [0.1, 0.01, 0.001],\n",
    "                                                           'n_estimators': [100,200,500,1000],\n",
    "                                                           'num_leaves': [20, 31, 40, 60, 80],\n",
    "                                                           'min_data_in_leaf': range(50,300, 100)}},\n",
    "          {'model':SVR(verbose=0), 'params':  {'C': [0.1, 1], #10, 100\n",
    "                                      'gamma': [0.1, 0.01],#1, , 0.001\n",
    "                                      'kernel': ['linear', 'rbf', 'sigmoid']}},# 'poly',\n",
    "          {'model':MLPRegressor(verbose=False,max_iter=20000, random_state=42), 'params':  {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,50), (75,35)],\n",
    "                                               'activation': ['relu','tanh'],#,'logistic'\n",
    "                                               'alpha': [0.0001, 0.05]}}\n",
    "          ]\n",
    "\n",
    "\n",
    "# Function to scale features\n",
    "def scale_features(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b49e55ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing RS inputs..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LC_Type1</th>\n",
       "      <th>LC_Type2</th>\n",
       "      <th>LC_Type3</th>\n",
       "      <th>LC_Type4</th>\n",
       "      <th>LC_Type5</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>sur_refl_b01</th>\n",
       "      <th>sur_refl_b02</th>\n",
       "      <th>...</th>\n",
       "      <th>runoff_sum</th>\n",
       "      <th>total_evaporation_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>snowmelt_sum</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>snow_density</th>\n",
       "      <th>snow_cover</th>\n",
       "      <th>dewpoint_temperature_2m</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>totalArea_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>2110</td>\n",
       "      <td>890</td>\n",
       "      <td>714</td>\n",
       "      <td>1096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.690267e-01</td>\n",
       "      <td>198.237289</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>265.185745</td>\n",
       "      <td>269.474932</td>\n",
       "      <td>0.979713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>151</td>\n",
       "      <td>2778</td>\n",
       "      <td>1434</td>\n",
       "      <td>1366</td>\n",
       "      <td>2417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.543760e-05</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>154.937485</td>\n",
       "      <td>0.102783</td>\n",
       "      <td>276.366584</td>\n",
       "      <td>281.858940</td>\n",
       "      <td>0.295989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>5245</td>\n",
       "      <td>1435</td>\n",
       "      <td>300</td>\n",
       "      <td>962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>100.002263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>281.229359</td>\n",
       "      <td>291.656452</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>580</td>\n",
       "      <td>5716</td>\n",
       "      <td>2978</td>\n",
       "      <td>635</td>\n",
       "      <td>2330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.360212e-06</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>161.781235</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>270.544548</td>\n",
       "      <td>274.700846</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>453</td>\n",
       "      <td>3206</td>\n",
       "      <td>757</td>\n",
       "      <td>374</td>\n",
       "      <td>727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.351754e-03</td>\n",
       "      <td>2.640788e-02</td>\n",
       "      <td>267.080388</td>\n",
       "      <td>26.630371</td>\n",
       "      <td>273.304184</td>\n",
       "      <td>282.790248</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>4203</td>\n",
       "      <td>1322</td>\n",
       "      <td>435</td>\n",
       "      <td>1066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.450581e-09</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>105.813136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.222176</td>\n",
       "      <td>287.991054</td>\n",
       "      <td>0.830562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2186</td>\n",
       "      <td>1518</td>\n",
       "      <td>171</td>\n",
       "      <td>201</td>\n",
       "      <td>273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.294075e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>180.705714</td>\n",
       "      <td>40.343750</td>\n",
       "      <td>281.538507</td>\n",
       "      <td>282.846760</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2479</td>\n",
       "      <td>-63</td>\n",
       "      <td>-45</td>\n",
       "      <td>2834</td>\n",
       "      <td>2798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.279286e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>180.694321</td>\n",
       "      <td>40.343750</td>\n",
       "      <td>278.835497</td>\n",
       "      <td>280.776448</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2100</td>\n",
       "      <td>-405</td>\n",
       "      <td>-370</td>\n",
       "      <td>5175</td>\n",
       "      <td>4772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.418032e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>194.436834</td>\n",
       "      <td>40.363200</td>\n",
       "      <td>275.874074</td>\n",
       "      <td>277.500503</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1823</td>\n",
       "      <td>-38</td>\n",
       "      <td>-39</td>\n",
       "      <td>7005</td>\n",
       "      <td>6951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.418032e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>194.436834</td>\n",
       "      <td>40.363200</td>\n",
       "      <td>275.874074</td>\n",
       "      <td>277.500503</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2070 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LC_Type1  LC_Type2  LC_Type3  LC_Type4  LC_Type5  Elevation  NDVI   EVI  \\\n",
       "0            8         8         4         4         4         76  2110   890   \n",
       "1            8         8         4         4         4        151  2778  1434   \n",
       "2            8         8         4         1         1        174  5245  1435   \n",
       "3            7         7         2         1         5        580  5716  2978   \n",
       "4            7         7         2         1         5        453  3206   757   \n",
       "...        ...       ...       ...       ...       ...        ...   ...   ...   \n",
       "2065         8         8         4         1         1        313  4203  1322   \n",
       "2066        15        15         9         7        10       2186  1518   171   \n",
       "2067        15        15         9         7        10       2479   -63   -45   \n",
       "2068        15        15         9         7        10       2100  -405  -370   \n",
       "2069        15        15         9         7        10       1823   -38   -39   \n",
       "\n",
       "      sur_refl_b01  sur_refl_b02  ...  runoff_sum  total_evaporation_sum  \\\n",
       "0              714          1096  ...    0.000868              -0.000535   \n",
       "1             1366          2417  ...    0.000046              -0.002125   \n",
       "2              300           962  ...    0.000249              -0.003539   \n",
       "3              635          2330  ...    0.001994              -0.000478   \n",
       "4              374           727  ...    0.000587              -0.000995   \n",
       "...            ...           ...  ...         ...                    ...   \n",
       "2065           435          1066  ...    0.000534              -0.002531   \n",
       "2066           201           273  ...    0.006850              -0.000637   \n",
       "2067          2834          2798  ...    0.006829              -0.001089   \n",
       "2068          5175          4772  ...    0.004876              -0.000546   \n",
       "2069          7005          6951  ...    0.004876              -0.000546   \n",
       "\n",
       "      snowfall_sum  snowmelt_sum    snow_depth  snow_density  snow_cover  \\\n",
       "0         0.000005  0.000000e+00  1.690267e-01    198.237289  100.000000   \n",
       "1         0.000000  1.543760e-05 -7.345365e-24    154.937485    0.102783   \n",
       "2         0.000000  0.000000e+00 -7.345365e-24    100.002263    0.000000   \n",
       "3         0.000000  3.360212e-06 -7.345365e-24    161.781235    0.082926   \n",
       "4         0.000000  4.351754e-03  2.640788e-02    267.080388   26.630371   \n",
       "...            ...           ...           ...           ...         ...   \n",
       "2065      0.000000  7.450581e-09 -7.345365e-24    105.813136    0.000000   \n",
       "2066      0.000000  6.294075e-03  1.344824e+01    180.705714   40.343750   \n",
       "2067      0.000000  6.279286e-03  1.344824e+01    180.694321   40.343750   \n",
       "2068      0.000000  3.418032e-03  1.344824e+01    194.436834   40.363200   \n",
       "2069      0.000000  3.418032e-03  1.344824e+01    194.436834   40.363200   \n",
       "\n",
       "      dewpoint_temperature_2m  temperature_2m  totalArea_km2  \n",
       "0                  265.185745      269.474932       0.979713  \n",
       "1                  276.366584      281.858940       0.295989  \n",
       "2                  281.229359      291.656452       0.250000  \n",
       "3                  270.544548      274.700846       0.250000  \n",
       "4                  273.304184      282.790248       0.250000  \n",
       "...                       ...             ...            ...  \n",
       "2065               280.222176      287.991054       0.830562  \n",
       "2066               281.538507      282.846760       0.250000  \n",
       "2067               278.835497      280.776448       0.250000  \n",
       "2068               275.874074      277.500503       0.250000  \n",
       "2069               275.874074      277.500503       0.250000  \n",
       "\n",
       "[2070 rows x 44 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read inputs \n",
    "print('Reading and processing RS inputs..')\n",
    "data = pd.read_csv('FireBurntArea_dataset_sameDay.csv', header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "100cdb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting to train and test sets..\n",
      "training set:  (1656, 43) (1656,) , testing set:  (414, 43) (414,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "print('Splitting to train and test sets..')\n",
    "all_indices = list(range(len(data)))\n",
    "\n",
    "train_ind, test_ind = train_test_split(all_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test = data.iloc[train_ind,:-1], data.iloc[test_ind,:-1]\n",
    "y_train, y_test = np.squeeze(data.iloc[train_ind,-1]), np.squeeze(data.iloc[test_ind,-1])\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_test_scaled = scale_features(X_train, X_test)  \n",
    "\n",
    "print('training set: ',X_train_scaled.shape, y_train.shape, ', testing set: ',X_test_scaled.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9c907e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def mean_absolute_scaled_error(y_true, y_pred, y_train):\n",
    "    \"\"\"\n",
    "    Compute the Mean Absolute Scaled Error (MASE).\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: array-like of shape (n_samples,) - Ground truth (correct) target values.\n",
    "    y_pred: array-like of shape (n_samples,) - Estimated target values.\n",
    "    y_train: array-like of shape (n_samples,) - Training data to calculate the naive forecast.\n",
    "\n",
    "    Returns:\n",
    "    mase: float - Mean Absolute Scaled Error.\n",
    "    \"\"\"\n",
    "    # Check for the length of y_train\n",
    "    if len(y_train) < 2:\n",
    "        raise ValueError(\"Length of y_train should be at least 2.\")\n",
    "\n",
    "    # Calculate MAE for the predictions\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Calculate the MAE of the one-step naive forecast method\n",
    "    naive_forecast = y_train[:-1]\n",
    "    naive_true = y_train[1:]\n",
    "    mae_naive = mean_absolute_error(naive_true, naive_forecast)\n",
    "\n",
    "    # Handle the case when naive MAE is zero to avoid division by zero\n",
    "    if mae_naive == 0:\n",
    "        return np.inf if mae != 0 else 0\n",
    "\n",
    "    # Calculate MASE\n",
    "    mase = mae / mae_naive\n",
    "\n",
    "    return mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2245f8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target;model;bestparam;inputs;trainDur;RMSE;MASE;testDur;RMSE;MASE\n",
      "LinearRegression;-;ALL;0.0044994354248046875;203.57051059912462;0.8638629124553519;0.00017952919006347656;200.85883636639008;0.851732098839674\n",
      "SGDRegressor;{'alpha': 1e-06, 'learning_rate': 'optimal', 'loss': 'huber', 'penalty': 'elasticnet'};ALL;1.7820420265197754;217.05073170880019;0.607353829947111;0.00046181678771972656;210.56539811402752;0.5703562484950959\n",
      "KNeighborsRegressor;{'n_neighbors': 21, 'p': 1, 'weights': 'distance'};ALL;0.3894217014312744;0.2771850068227421;0.00011249465472584327;0.06293129920959473;195.57485938794005;0.7494784641599136\n",
      "RandomForestRegressor;{'max_depth': 18, 'min_samples_leaf': 6, 'min_samples_split': 2, 'n_estimators': 70};ALL;68.96423745155334;161.35429933740275;0.5765156789844849;0.014795303344726562;202.34503668150137;0.7850969210258664\n",
      "ExtraTreesRegressor;{'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 70};ALL;15.750592947006226;130.89224314664864;0.4191700640562581;0.018038511276245117;196.58219372459183;0.7287371418943867\n",
      "LGBMRegressor;learning_rate: 0.01, min_data_in_leaf: 50, n_estimators: 1000, num_leaves: 60;ALL;2.0981104373931885;130.43556979011865;0.4357418989692459;0.0024585723876953125;201.5396046195209;0.7903306166459718\n",
      "SVR;{'C': 1, 'gamma': 0.1, 'kernel': 'sigmoid'};ALL;1.0914297103881836;218.35681201339554;0.7024018304905963;0.04385209083557129;212.2437914048858;0.6696613193079509\n",
      "MLPRegressor;{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50)};ALL;108.81469321250916;118.40206468554227;0.164485387802785;0.0015213489532470703;228.4690462800259;0.9103329255387712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "print(f'Target;model;bestparam;inputs;trainDur;RMSE;MASE;testDur;RMSE;MASE')\n",
    "\n",
    "for model in models:\n",
    "    print(str(model['model']).split('(')[0],end=';')\n",
    "\n",
    "    # hyperparameter tuning\n",
    "    if str(model['model']).split('(')[0] != 'LinearRegression' and str(model['model']).split('(')[0] != 'LGBMRegressor':\n",
    "        model_final = GridSearchCV(model['model'], model['params'], cv=10, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)#n_iter=15,\n",
    "    elif str(model['model']).split('(')[0] == 'LGBMRegressor':\n",
    "        model_final = LGBMRegressor(learning_rate=0.01, min_data_in_leaf=50, n_estimators=1000, num_leaves=60, n_jobs=-1, verbose=-1,force_col_wise=True)\n",
    "    else:\n",
    "        model_final = model['model']\n",
    "#     model_final = GridSearchCV(model['model'], model['params'], cv=10, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)#n_iter=15,\n",
    "\n",
    "    # Train model\n",
    "    start_train = time.time()\n",
    "    model_final.fit(X_train_scaled, y_train)\n",
    "    end_train = time.time()\n",
    "\n",
    "    # Evaluate training performance\n",
    "    y_pred_train = model_final.predict(X_train_scaled)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    mase_train = mean_absolute_scaled_error(y_train, y_pred_train, y_train)\n",
    "    train_duration = end_train - start_train\n",
    "\n",
    "    if str(model['model']).split('(')[0] != 'LinearRegression' and str(model['model']).split('(')[0] != 'LGBMRegressor':\n",
    "        print(f'{model_final.best_params_};ALL;{train_duration};{rmse_train};{mase_train}',end=';')\n",
    "    elif str(model['model']).split('(')[0] == 'LGBMRegressor':\n",
    "        print(f'learning_rate: 0.01, min_data_in_leaf: 50, n_estimators: 1000, num_leaves: 60;ALL;{train_duration};{rmse_train};{mase_train}',end=';')\n",
    "    else:\n",
    "        print(f'-;ALL;{train_duration};{rmse_train};{mase_train}',end=';')\n",
    "\n",
    "    # Test model\n",
    "    start_test = time.time()\n",
    "    y_pred_test = model_final.predict(X_test_scaled)\n",
    "    end_test = time.time()\n",
    "\n",
    "    # Evaluate testing performance\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    mase_test = mean_absolute_scaled_error(y_test, y_pred_test, y_train)\n",
    "    test_duration = end_test - start_test\n",
    "\n",
    "    print(f'{test_duration};{rmse_test};{mase_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68235546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fed9e2eb",
   "metadata": {},
   "source": [
    "## conventional ML - Fire Duration prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "373d8f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, sys, os\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "import pandas as pd\n",
    "# pip install scikit-learn==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "645b2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into pandas dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# !pip install sktime\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# !pip install PrettyTable\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "models = [{'model': LinearRegression(), 'params': {}},\n",
    "          {'model': SGDRegressor(max_iter=10000, random_state=42), 'params': {'alpha': 10.0 ** -np.arange(1, 7),\n",
    "                                                                               'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n",
    "                                                                               'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                                                                               'learning_rate': ['constant', 'optimal', 'invscaling']}},\n",
    "          {'model': KNeighborsRegressor(n_jobs=-1), 'params': {'n_neighbors': range(3, 23, 3), 'weights': ['uniform', 'distance'], 'p': [1, 2]}},\n",
    "\n",
    "          {'model': RandomForestRegressor(verbose=0, n_jobs=-1, random_state=42), 'params': {'n_estimators': [10, 20, 50, 70],\n",
    "                                                        'max_depth': range(3,23,3),\n",
    "                                                        'min_samples_split': [2, 4, 6],\n",
    "                                                        'min_samples_leaf': [2, 4, 6]}},\n",
    "          {'model': ExtraTreesRegressor(verbose=0, n_jobs=-1, random_state=42), 'params': {'n_estimators': [10, 20, 50, 70],\n",
    "                                                        'max_depth': range(3,23,3),\n",
    "                                                        'min_samples_split': [2, 4, 6],\n",
    "                                                        'min_samples_leaf': [2, 4, 6]}},          \n",
    "          {'model':LGBMRegressor(n_jobs=-1, verbose=-1,force_col_wise=True, random_state=42), 'params': {'learning_rate': [0.1, 0.01, 0.001],\n",
    "                                                           'n_estimators': [100,200,500,1000],\n",
    "                                                           'num_leaves': [20, 31, 40, 60, 80],\n",
    "                                                           'min_data_in_leaf': range(50,300, 100)}},\n",
    "          {'model':SVR(verbose=0), 'params':  {'C': [0.1, 1], #10, 100\n",
    "                                      'gamma': [0.1, 0.01],#1, , 0.001\n",
    "                                      'kernel': ['linear', 'rbf', 'sigmoid']}},# 'poly',\n",
    "          {'model':MLPRegressor(verbose=False,max_iter=20000, random_state=42), 'params':  {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,50), (75,35)],\n",
    "                                               'activation': ['relu','tanh'],#,'logistic'\n",
    "                                               'alpha': [0.0001, 0.05]}}\n",
    "          ]\n",
    "\n",
    "\n",
    "# Function to scale features\n",
    "def scale_features(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47a65f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing RS inputs..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LC_Type1</th>\n",
       "      <th>LC_Type2</th>\n",
       "      <th>LC_Type3</th>\n",
       "      <th>LC_Type4</th>\n",
       "      <th>LC_Type5</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>sur_refl_b01</th>\n",
       "      <th>sur_refl_b02</th>\n",
       "      <th>...</th>\n",
       "      <th>runoff_sum</th>\n",
       "      <th>total_evaporation_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>snowmelt_sum</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>snow_density</th>\n",
       "      <th>snow_cover</th>\n",
       "      <th>dewpoint_temperature_2m</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>2110</td>\n",
       "      <td>890</td>\n",
       "      <td>714</td>\n",
       "      <td>1096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.690267e-01</td>\n",
       "      <td>198.237289</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>265.185745</td>\n",
       "      <td>269.474932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>151</td>\n",
       "      <td>2778</td>\n",
       "      <td>1434</td>\n",
       "      <td>1366</td>\n",
       "      <td>2417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.543760e-05</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>154.937485</td>\n",
       "      <td>0.102783</td>\n",
       "      <td>276.366584</td>\n",
       "      <td>281.858940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>5245</td>\n",
       "      <td>1435</td>\n",
       "      <td>300</td>\n",
       "      <td>962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>100.002263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>281.229359</td>\n",
       "      <td>291.656452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>580</td>\n",
       "      <td>5716</td>\n",
       "      <td>2978</td>\n",
       "      <td>635</td>\n",
       "      <td>2330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.360212e-06</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>161.781235</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>270.544548</td>\n",
       "      <td>274.700846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>453</td>\n",
       "      <td>3206</td>\n",
       "      <td>757</td>\n",
       "      <td>374</td>\n",
       "      <td>727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.351754e-03</td>\n",
       "      <td>2.640788e-02</td>\n",
       "      <td>267.080388</td>\n",
       "      <td>26.630371</td>\n",
       "      <td>273.304184</td>\n",
       "      <td>282.790248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>4203</td>\n",
       "      <td>1322</td>\n",
       "      <td>435</td>\n",
       "      <td>1066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.450581e-09</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>105.813136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.222176</td>\n",
       "      <td>287.991054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2186</td>\n",
       "      <td>1518</td>\n",
       "      <td>171</td>\n",
       "      <td>201</td>\n",
       "      <td>273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.294075e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>180.705714</td>\n",
       "      <td>40.343750</td>\n",
       "      <td>281.538507</td>\n",
       "      <td>282.846760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2479</td>\n",
       "      <td>-63</td>\n",
       "      <td>-45</td>\n",
       "      <td>2834</td>\n",
       "      <td>2798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.279286e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>180.694321</td>\n",
       "      <td>40.343750</td>\n",
       "      <td>278.835497</td>\n",
       "      <td>280.776448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2100</td>\n",
       "      <td>-405</td>\n",
       "      <td>-370</td>\n",
       "      <td>5175</td>\n",
       "      <td>4772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.418032e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>194.436834</td>\n",
       "      <td>40.363200</td>\n",
       "      <td>275.874074</td>\n",
       "      <td>277.500503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1823</td>\n",
       "      <td>-38</td>\n",
       "      <td>-39</td>\n",
       "      <td>7005</td>\n",
       "      <td>6951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.418032e-03</td>\n",
       "      <td>1.344824e+01</td>\n",
       "      <td>194.436834</td>\n",
       "      <td>40.363200</td>\n",
       "      <td>275.874074</td>\n",
       "      <td>277.500503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2070 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LC_Type1  LC_Type2  LC_Type3  LC_Type4  LC_Type5  Elevation  NDVI   EVI  \\\n",
       "0            8         8         4         4         4         76  2110   890   \n",
       "1            8         8         4         4         4        151  2778  1434   \n",
       "2            8         8         4         1         1        174  5245  1435   \n",
       "3            7         7         2         1         5        580  5716  2978   \n",
       "4            7         7         2         1         5        453  3206   757   \n",
       "...        ...       ...       ...       ...       ...        ...   ...   ...   \n",
       "2065         8         8         4         1         1        313  4203  1322   \n",
       "2066        15        15         9         7        10       2186  1518   171   \n",
       "2067        15        15         9         7        10       2479   -63   -45   \n",
       "2068        15        15         9         7        10       2100  -405  -370   \n",
       "2069        15        15         9         7        10       1823   -38   -39   \n",
       "\n",
       "      sur_refl_b01  sur_refl_b02  ...  runoff_sum  total_evaporation_sum  \\\n",
       "0              714          1096  ...    0.000868              -0.000535   \n",
       "1             1366          2417  ...    0.000046              -0.002125   \n",
       "2              300           962  ...    0.000249              -0.003539   \n",
       "3              635          2330  ...    0.001994              -0.000478   \n",
       "4              374           727  ...    0.000587              -0.000995   \n",
       "...            ...           ...  ...         ...                    ...   \n",
       "2065           435          1066  ...    0.000534              -0.002531   \n",
       "2066           201           273  ...    0.006850              -0.000637   \n",
       "2067          2834          2798  ...    0.006829              -0.001089   \n",
       "2068          5175          4772  ...    0.004876              -0.000546   \n",
       "2069          7005          6951  ...    0.004876              -0.000546   \n",
       "\n",
       "      snowfall_sum  snowmelt_sum    snow_depth  snow_density  snow_cover  \\\n",
       "0         0.000005  0.000000e+00  1.690267e-01    198.237289  100.000000   \n",
       "1         0.000000  1.543760e-05 -7.345365e-24    154.937485    0.102783   \n",
       "2         0.000000  0.000000e+00 -7.345365e-24    100.002263    0.000000   \n",
       "3         0.000000  3.360212e-06 -7.345365e-24    161.781235    0.082926   \n",
       "4         0.000000  4.351754e-03  2.640788e-02    267.080388   26.630371   \n",
       "...            ...           ...           ...           ...         ...   \n",
       "2065      0.000000  7.450581e-09 -7.345365e-24    105.813136    0.000000   \n",
       "2066      0.000000  6.294075e-03  1.344824e+01    180.705714   40.343750   \n",
       "2067      0.000000  6.279286e-03  1.344824e+01    180.694321   40.343750   \n",
       "2068      0.000000  3.418032e-03  1.344824e+01    194.436834   40.363200   \n",
       "2069      0.000000  3.418032e-03  1.344824e+01    194.436834   40.363200   \n",
       "\n",
       "      dewpoint_temperature_2m  temperature_2m  Duration  \n",
       "0                  265.185745      269.474932         1  \n",
       "1                  276.366584      281.858940         1  \n",
       "2                  281.229359      291.656452         1  \n",
       "3                  270.544548      274.700846         1  \n",
       "4                  273.304184      282.790248         1  \n",
       "...                       ...             ...       ...  \n",
       "2065               280.222176      287.991054         1  \n",
       "2066               281.538507      282.846760         1  \n",
       "2067               278.835497      280.776448         1  \n",
       "2068               275.874074      277.500503         1  \n",
       "2069               275.874074      277.500503         1  \n",
       "\n",
       "[2070 rows x 44 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read inputs \n",
    "print('Reading and processing RS inputs..')\n",
    "data = pd.read_csv('FireDuration_dataset_sameDay.csv', header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c78e6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting to train and test sets..\n",
      "training set:  (1656, 43) (1656,) , testing set:  (414, 43) (414,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "print('Splitting to train and test sets..')\n",
    "all_indices = list(range(len(data)))\n",
    "\n",
    "train_ind, test_ind = train_test_split(all_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test = data.iloc[train_ind,:-1], data.iloc[test_ind,:-1]\n",
    "y_train, y_test = np.squeeze(data.iloc[train_ind,-1]), np.squeeze(data.iloc[test_ind,-1])\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_test_scaled = scale_features(X_train, X_test)  \n",
    "\n",
    "print('training set: ',X_train_scaled.shape, y_train.shape, ', testing set: ',X_test_scaled.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbb3d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def mean_absolute_scaled_error(y_true, y_pred, y_train):\n",
    "    \"\"\"\n",
    "    Compute the Mean Absolute Scaled Error (MASE).\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: array-like of shape (n_samples,) - Ground truth (correct) target values.\n",
    "    y_pred: array-like of shape (n_samples,) - Estimated target values.\n",
    "    y_train: array-like of shape (n_samples,) - Training data to calculate the naive forecast.\n",
    "\n",
    "    Returns:\n",
    "    mase: float - Mean Absolute Scaled Error.\n",
    "    \"\"\"\n",
    "    # Check for the length of y_train\n",
    "    if len(y_train) < 2:\n",
    "        raise ValueError(\"Length of y_train should be at least 2.\")\n",
    "\n",
    "    # Calculate MAE for the predictions\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Calculate the MAE of the one-step naive forecast method\n",
    "    naive_forecast = y_train[:-1]\n",
    "    naive_true = y_train[1:]\n",
    "    mae_naive = mean_absolute_error(naive_true, naive_forecast)\n",
    "\n",
    "    # Handle the case when naive MAE is zero to avoid division by zero\n",
    "    if mae_naive == 0:\n",
    "        return np.inf if mae != 0 else 0\n",
    "\n",
    "    # Calculate MASE\n",
    "    mase = mae / mae_naive\n",
    "\n",
    "    return mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5df1264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target;model;bestparam;inputs;trainDur;RMSE;MAE;MASE;testDur;RMSE;MAE;MASE\n",
      "LinearRegression;-;ALL;0.003535032272338867;8.80338080016759;0.7741059723734197;0.00014781951904296875;8.452727855114096;0.7447388922094847\n",
      "SGDRegressor;{'alpha': 0.001, 'learning_rate': 'optimal', 'loss': 'epsilon_insensitive', 'penalty': 'l1'};ALL;1.797248363494873;9.90610054798206;0.6407672450727989;0.0005033016204833984;9.567017554254264;0.6168814622439749\n",
      "KNeighborsRegressor;{'n_neighbors': 15, 'p': 1, 'weights': 'distance'};ALL;0.4338548183441162;0.0;0.0;0.061661720275878906;7.878021682328089;0.657088467104622\n",
      "RandomForestRegressor;{'max_depth': 15, 'min_samples_leaf': 6, 'min_samples_split': 2, 'n_estimators': 50};ALL;64.70977115631104;5.502399079286247;0.44083066639945895;0.014793157577514648;7.4565969258642255;0.6209494386775359\n",
      "ExtraTreesRegressor;{'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 50};ALL;15.695321083068848;4.127603259772901;0.3237490167089182;0.011482477188110352;7.093838054088219;0.5855450525568285\n",
      "LGBMRegressor;learning_rate: 0.01, min_data_in_leaf: 50, n_estimators: 1000, num_leaves: 60;ALL;1.7937099933624268;3.789747847095221;0.30596213079846213;0.002175569534301758;7.244497634691781;0.6223824416911135\n",
      "SVR;{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'};ALL;1.123103141784668;9.362441007275976;0.5373029801133411;0.04921531677246094;9.18170977917957;0.5814005530239769\n",
      "MLPRegressor;{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50)};ALL;19.197602033615112;0.9353197830260513;0.08822971248745365;0.0008754730224609375;8.572066528782448;0.7244348799929988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "print(f'Target;model;bestparam;inputs;trainDur;RMSE;MAE;MASE;testDur;RMSE;MAE;MASE')\n",
    "\n",
    "for model in models:\n",
    "    print(str(model['model']).split('(')[0],end=';')\n",
    "\n",
    "    # hyperparameter tuning\n",
    "    if str(model['model']).split('(')[0] != 'LinearRegression' and str(model['model']).split('(')[0] != 'LGBMRegressor':\n",
    "        model_final = GridSearchCV(model['model'], model['params'], cv=10, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)#n_iter=15,\n",
    "    elif str(model['model']).split('(')[0] == 'LGBMRegressor':\n",
    "        model_final = LGBMRegressor(learning_rate=0.01, min_data_in_leaf=50, n_estimators=1000, num_leaves=60, n_jobs=-1, verbose=-1,force_col_wise=True)\n",
    "    else:\n",
    "        model_final = model['model']\n",
    "#     model_final = GridSearchCV(model['model'], model['params'], cv=10, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)#n_iter=15,\n",
    "\n",
    "    # Train model\n",
    "    start_train = time.time()\n",
    "    model_final.fit(X_train_scaled, y_train)\n",
    "    end_train = time.time()\n",
    "\n",
    "    # Evaluate training performance\n",
    "    y_pred_train = model_final.predict(X_train_scaled)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    mase_train = mean_absolute_scaled_error(y_train, y_pred_train, y_train)\n",
    "    train_duration = end_train - start_train\n",
    "\n",
    "    if str(model['model']).split('(')[0] != 'LinearRegression' and str(model['model']).split('(')[0] != 'LGBMRegressor':\n",
    "        print(f'{model_final.best_params_};ALL;{train_duration};{rmse_train};{mase_train}',end=';')\n",
    "    elif str(model['model']).split('(')[0] == 'LGBMRegressor':\n",
    "        print(f'learning_rate: 0.01, min_data_in_leaf: 50, n_estimators: 1000, num_leaves: 60;ALL;{train_duration};{rmse_train};{mase_train}',end=';')\n",
    "    else:\n",
    "        print(f'-;ALL;{train_duration};{rmse_train};{mase_train}',end=';')\n",
    "\n",
    "    # Test model\n",
    "    start_test = time.time()\n",
    "    y_pred_test = model_final.predict(X_test_scaled)\n",
    "    end_test = time.time()\n",
    "\n",
    "    # Evaluate testing performance\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    mase_test = mean_absolute_scaled_error(y_test, y_pred_test, y_train)\n",
    "    test_duration = end_test - start_test\n",
    "\n",
    "    print(f'{test_duration};{rmse_test};{mase_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d74bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021bc84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
